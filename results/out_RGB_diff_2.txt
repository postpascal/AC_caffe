I0429 19:35:27.026839 11879 caffe.cpp:113] Use GPU with device ID 0
I0429 19:35:27.918977 11879 caffe.cpp:121] Starting Optimization
I0429 19:35:27.919088 11879 solver.cpp:32] Initializing solver from parameters: 
test_iter: 100
test_interval: 200
base_lr: 0.005
display: 20
max_iter: 4000
lr_policy: "step"
gamma: 0.1
weight_decay: 0.01
stepsize: 4000
snapshot_prefix: "Acre/acre"
solver_mode: GPU
net: "Acre/ac_train_test.prototxt"
solver_type: SGD
I0429 19:35:27.919131 11879 solver.cpp:70] Creating training net from net file: Acre/ac_train_test.prototxt
I0429 19:35:27.919809 11879 net.cpp:287] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0429 19:35:27.920058 11879 net.cpp:42] Initializing net from parameters: 
name: "ac_re"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 103.939
  }
  data_param {
    source: "Acre/Acre_train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 7
    group: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 5
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-ucf"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8-ucf"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8-ucf"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8-ucf"
  bottom: "label"
  top: "accuracy"
}
I0429 19:35:27.920302 11879 layer_factory.hpp:74] Creating layer data
I0429 19:35:27.920336 11879 net.cpp:90] Creating Layer data
I0429 19:35:27.920382 11879 net.cpp:368] data -> data
I0429 19:35:27.920426 11879 net.cpp:368] data -> label
I0429 19:35:27.920450 11879 net.cpp:120] Setting up data
I0429 19:35:27.920919 11879 db_lmdb.cpp:22] Opened lmdb Acre/Acre_train_lmdb
I0429 19:35:27.921953 11879 data_layer.cpp:52] output data size: 32,12,227,227
I0429 19:35:27.997336 11879 net.cpp:127] Top shape: 32 12 227 227 (19787136)
I0429 19:35:27.997364 11879 net.cpp:127] Top shape: 32 (32)
I0429 19:35:27.997378 11879 layer_factory.hpp:74] Creating layer label_data_1_split
I0429 19:35:27.997398 11879 net.cpp:90] Creating Layer label_data_1_split
I0429 19:35:27.997433 11879 net.cpp:410] label_data_1_split <- label
I0429 19:35:27.997483 11879 net.cpp:368] label_data_1_split -> label_data_1_split_0
I0429 19:35:27.997505 11879 net.cpp:368] label_data_1_split -> label_data_1_split_1
I0429 19:35:27.997521 11879 net.cpp:120] Setting up label_data_1_split
I0429 19:35:27.997558 11879 net.cpp:127] Top shape: 32 (32)
I0429 19:35:27.997570 11879 net.cpp:127] Top shape: 32 (32)
I0429 19:35:27.997578 11879 layer_factory.hpp:74] Creating layer conv1
I0429 19:35:27.997604 11879 net.cpp:90] Creating Layer conv1
I0429 19:35:27.997616 11879 net.cpp:410] conv1 <- data
I0429 19:35:27.997630 11879 net.cpp:368] conv1 -> conv1
I0429 19:35:27.997673 11879 net.cpp:120] Setting up conv1
I0429 19:35:29.889698 11879 net.cpp:127] Top shape: 32 96 109 109 (36498432)
I0429 19:35:29.889741 11879 layer_factory.hpp:74] Creating layer relu1
I0429 19:35:29.889757 11879 net.cpp:90] Creating Layer relu1
I0429 19:35:29.889766 11879 net.cpp:410] relu1 <- conv1
I0429 19:35:29.889780 11879 net.cpp:357] relu1 -> conv1 (in-place)
I0429 19:35:29.889793 11879 net.cpp:120] Setting up relu1
I0429 19:35:29.889920 11879 net.cpp:127] Top shape: 32 96 109 109 (36498432)
I0429 19:35:29.889935 11879 layer_factory.hpp:74] Creating layer pool1
I0429 19:35:29.889952 11879 net.cpp:90] Creating Layer pool1
I0429 19:35:29.889960 11879 net.cpp:410] pool1 <- conv1
I0429 19:35:29.889971 11879 net.cpp:368] pool1 -> pool1
I0429 19:35:29.889983 11879 net.cpp:120] Setting up pool1
I0429 19:35:29.890302 11879 net.cpp:127] Top shape: 32 96 54 54 (8957952)
I0429 19:35:29.890317 11879 layer_factory.hpp:74] Creating layer norm1
I0429 19:35:29.890331 11879 net.cpp:90] Creating Layer norm1
I0429 19:35:29.890337 11879 net.cpp:410] norm1 <- pool1
I0429 19:35:29.890347 11879 net.cpp:368] norm1 -> norm1
I0429 19:35:29.890386 11879 net.cpp:120] Setting up norm1
I0429 19:35:29.890404 11879 net.cpp:127] Top shape: 32 96 54 54 (8957952)
I0429 19:35:29.890411 11879 layer_factory.hpp:74] Creating layer conv2
I0429 19:35:29.890425 11879 net.cpp:90] Creating Layer conv2
I0429 19:35:29.890432 11879 net.cpp:410] conv2 <- norm1
I0429 19:35:29.890444 11879 net.cpp:368] conv2 -> conv2
I0429 19:35:29.890456 11879 net.cpp:120] Setting up conv2
I0429 19:35:29.942246 11879 net.cpp:127] Top shape: 32 384 24 24 (7077888)
I0429 19:35:29.942293 11879 layer_factory.hpp:74] Creating layer relu2
I0429 19:35:29.942309 11879 net.cpp:90] Creating Layer relu2
I0429 19:35:29.942318 11879 net.cpp:410] relu2 <- conv2
I0429 19:35:29.942330 11879 net.cpp:357] relu2 -> conv2 (in-place)
I0429 19:35:29.942343 11879 net.cpp:120] Setting up relu2
I0429 19:35:29.942467 11879 net.cpp:127] Top shape: 32 384 24 24 (7077888)
I0429 19:35:29.942479 11879 layer_factory.hpp:74] Creating layer pool2
I0429 19:35:29.942494 11879 net.cpp:90] Creating Layer pool2
I0429 19:35:29.942502 11879 net.cpp:410] pool2 <- conv2
I0429 19:35:29.942512 11879 net.cpp:368] pool2 -> pool2
I0429 19:35:29.942524 11879 net.cpp:120] Setting up pool2
I0429 19:35:29.942656 11879 net.cpp:127] Top shape: 32 384 12 12 (1769472)
I0429 19:35:29.942668 11879 layer_factory.hpp:74] Creating layer norm2
I0429 19:35:29.942682 11879 net.cpp:90] Creating Layer norm2
I0429 19:35:29.942690 11879 net.cpp:410] norm2 <- pool2
I0429 19:35:29.942699 11879 net.cpp:368] norm2 -> norm2
I0429 19:35:29.942711 11879 net.cpp:120] Setting up norm2
I0429 19:35:29.942723 11879 net.cpp:127] Top shape: 32 384 12 12 (1769472)
I0429 19:35:29.942731 11879 layer_factory.hpp:74] Creating layer conv3
I0429 19:35:29.942747 11879 net.cpp:90] Creating Layer conv3
I0429 19:35:29.942755 11879 net.cpp:410] conv3 <- norm2
I0429 19:35:29.942765 11879 net.cpp:368] conv3 -> conv3
I0429 19:35:29.942780 11879 net.cpp:120] Setting up conv3
I0429 19:35:30.279909 11879 net.cpp:127] Top shape: 32 512 10 10 (1638400)
I0429 19:35:30.279952 11879 layer_factory.hpp:74] Creating layer relu3
I0429 19:35:30.279966 11879 net.cpp:90] Creating Layer relu3
I0429 19:35:30.279975 11879 net.cpp:410] relu3 <- conv3
I0429 19:35:30.279988 11879 net.cpp:357] relu3 -> conv3 (in-place)
I0429 19:35:30.280000 11879 net.cpp:120] Setting up relu3
I0429 19:35:30.280128 11879 net.cpp:127] Top shape: 32 512 10 10 (1638400)
I0429 19:35:30.280143 11879 layer_factory.hpp:74] Creating layer conv4
I0429 19:35:30.280158 11879 net.cpp:90] Creating Layer conv4
I0429 19:35:30.280165 11879 net.cpp:410] conv4 <- conv3
I0429 19:35:30.280179 11879 net.cpp:368] conv4 -> conv4
I0429 19:35:30.280192 11879 net.cpp:120] Setting up conv4
I0429 19:35:30.465682 11879 net.cpp:127] Top shape: 32 512 8 8 (1048576)
I0429 19:35:30.465718 11879 layer_factory.hpp:74] Creating layer relu4
I0429 19:35:30.465734 11879 net.cpp:90] Creating Layer relu4
I0429 19:35:30.465744 11879 net.cpp:410] relu4 <- conv4
I0429 19:35:30.465755 11879 net.cpp:357] relu4 -> conv4 (in-place)
I0429 19:35:30.465769 11879 net.cpp:120] Setting up relu4
I0429 19:35:30.466074 11879 net.cpp:127] Top shape: 32 512 8 8 (1048576)
I0429 19:35:30.466089 11879 layer_factory.hpp:74] Creating layer conv5
I0429 19:35:30.466105 11879 net.cpp:90] Creating Layer conv5
I0429 19:35:30.466114 11879 net.cpp:410] conv5 <- conv4
I0429 19:35:30.466125 11879 net.cpp:368] conv5 -> conv5
I0429 19:35:30.466137 11879 net.cpp:120] Setting up conv5
I0429 19:35:30.516612 11879 net.cpp:127] Top shape: 32 384 8 8 (786432)
I0429 19:35:30.516651 11879 layer_factory.hpp:74] Creating layer relu5
I0429 19:35:30.516667 11879 net.cpp:90] Creating Layer relu5
I0429 19:35:30.516676 11879 net.cpp:410] relu5 <- conv5
I0429 19:35:30.516691 11879 net.cpp:357] relu5 -> conv5 (in-place)
I0429 19:35:30.516705 11879 net.cpp:120] Setting up relu5
I0429 19:35:30.516834 11879 net.cpp:127] Top shape: 32 384 8 8 (786432)
I0429 19:35:30.516846 11879 layer_factory.hpp:74] Creating layer pool5
I0429 19:35:30.516863 11879 net.cpp:90] Creating Layer pool5
I0429 19:35:30.516870 11879 net.cpp:410] pool5 <- conv5
I0429 19:35:30.516907 11879 net.cpp:368] pool5 -> pool5
I0429 19:35:30.516921 11879 net.cpp:120] Setting up pool5
I0429 19:35:30.517046 11879 net.cpp:127] Top shape: 32 384 4 4 (196608)
I0429 19:35:30.517060 11879 layer_factory.hpp:74] Creating layer fc6
I0429 19:35:30.517081 11879 net.cpp:90] Creating Layer fc6
I0429 19:35:30.517089 11879 net.cpp:410] fc6 <- pool5
I0429 19:35:30.517101 11879 net.cpp:368] fc6 -> fc6
I0429 19:35:30.517117 11879 net.cpp:120] Setting up fc6
I0429 19:35:30.561417 11879 net.cpp:127] Top shape: 32 128 (4096)
I0429 19:35:30.561477 11879 layer_factory.hpp:74] Creating layer relu6
I0429 19:35:30.561525 11879 net.cpp:90] Creating Layer relu6
I0429 19:35:30.561537 11879 net.cpp:410] relu6 <- fc6
I0429 19:35:30.561553 11879 net.cpp:357] relu6 -> fc6 (in-place)
I0429 19:35:30.561566 11879 net.cpp:120] Setting up relu6
I0429 19:35:30.561727 11879 net.cpp:127] Top shape: 32 128 (4096)
I0429 19:35:30.561739 11879 layer_factory.hpp:74] Creating layer drop6
I0429 19:35:30.561764 11879 net.cpp:90] Creating Layer drop6
I0429 19:35:30.561770 11879 net.cpp:410] drop6 <- fc6
I0429 19:35:30.561784 11879 net.cpp:357] drop6 -> fc6 (in-place)
I0429 19:35:30.561800 11879 net.cpp:120] Setting up drop6
I0429 19:35:30.561820 11879 net.cpp:127] Top shape: 32 128 (4096)
I0429 19:35:30.561828 11879 layer_factory.hpp:74] Creating layer fc7
I0429 19:35:30.561841 11879 net.cpp:90] Creating Layer fc7
I0429 19:35:30.561847 11879 net.cpp:410] fc7 <- fc6
I0429 19:35:30.561861 11879 net.cpp:368] fc7 -> fc7
I0429 19:35:30.561877 11879 net.cpp:120] Setting up fc7
I0429 19:35:30.562362 11879 net.cpp:127] Top shape: 32 64 (2048)
I0429 19:35:30.562377 11879 layer_factory.hpp:74] Creating layer relu7
I0429 19:35:30.562391 11879 net.cpp:90] Creating Layer relu7
I0429 19:35:30.562397 11879 net.cpp:410] relu7 <- fc7
I0429 19:35:30.562407 11879 net.cpp:357] relu7 -> fc7 (in-place)
I0429 19:35:30.562417 11879 net.cpp:120] Setting up relu7
I0429 19:35:30.562815 11879 net.cpp:127] Top shape: 32 64 (2048)
I0429 19:35:30.562830 11879 layer_factory.hpp:74] Creating layer drop7
I0429 19:35:30.562844 11879 net.cpp:90] Creating Layer drop7
I0429 19:35:30.562852 11879 net.cpp:410] drop7 <- fc7
I0429 19:35:30.562862 11879 net.cpp:357] drop7 -> fc7 (in-place)
I0429 19:35:30.562872 11879 net.cpp:120] Setting up drop7
I0429 19:35:30.562885 11879 net.cpp:127] Top shape: 32 64 (2048)
I0429 19:35:30.562891 11879 layer_factory.hpp:74] Creating layer fc8-ucf
I0429 19:35:30.562903 11879 net.cpp:90] Creating Layer fc8-ucf
I0429 19:35:30.562909 11879 net.cpp:410] fc8-ucf <- fc7
I0429 19:35:30.562922 11879 net.cpp:368] fc8-ucf -> fc8-ucf
I0429 19:35:30.562938 11879 net.cpp:120] Setting up fc8-ucf
I0429 19:35:30.562997 11879 net.cpp:127] Top shape: 32 10 (320)
I0429 19:35:30.563014 11879 layer_factory.hpp:74] Creating layer fc8-ucf_fc8-ucf_0_split
I0429 19:35:30.563024 11879 net.cpp:90] Creating Layer fc8-ucf_fc8-ucf_0_split
I0429 19:35:30.563031 11879 net.cpp:410] fc8-ucf_fc8-ucf_0_split <- fc8-ucf
I0429 19:35:30.563042 11879 net.cpp:368] fc8-ucf_fc8-ucf_0_split -> fc8-ucf_fc8-ucf_0_split_0
I0429 19:35:30.563055 11879 net.cpp:368] fc8-ucf_fc8-ucf_0_split -> fc8-ucf_fc8-ucf_0_split_1
I0429 19:35:30.563066 11879 net.cpp:120] Setting up fc8-ucf_fc8-ucf_0_split
I0429 19:35:30.563076 11879 net.cpp:127] Top shape: 32 10 (320)
I0429 19:35:30.563086 11879 net.cpp:127] Top shape: 32 10 (320)
I0429 19:35:30.563092 11879 layer_factory.hpp:74] Creating layer loss
I0429 19:35:30.563105 11879 net.cpp:90] Creating Layer loss
I0429 19:35:30.563112 11879 net.cpp:410] loss <- fc8-ucf_fc8-ucf_0_split_0
I0429 19:35:30.563122 11879 net.cpp:410] loss <- label_data_1_split_0
I0429 19:35:30.563130 11879 net.cpp:368] loss -> loss
I0429 19:35:30.563143 11879 net.cpp:120] Setting up loss
I0429 19:35:30.563163 11879 layer_factory.hpp:74] Creating layer loss
I0429 19:35:30.563320 11879 net.cpp:127] Top shape: (1)
I0429 19:35:30.563333 11879 net.cpp:129]     with loss weight 1
I0429 19:35:30.563362 11879 layer_factory.hpp:74] Creating layer accuracy
I0429 19:35:30.563397 11879 net.cpp:90] Creating Layer accuracy
I0429 19:35:30.563406 11879 net.cpp:410] accuracy <- fc8-ucf_fc8-ucf_0_split_1
I0429 19:35:30.563416 11879 net.cpp:410] accuracy <- label_data_1_split_1
I0429 19:35:30.563424 11879 net.cpp:368] accuracy -> accuracy
I0429 19:35:30.563436 11879 net.cpp:120] Setting up accuracy
I0429 19:35:30.563449 11879 net.cpp:127] Top shape: (1)
I0429 19:35:30.563457 11879 net.cpp:194] accuracy does not need backward computation.
I0429 19:35:30.563465 11879 net.cpp:192] loss needs backward computation.
I0429 19:35:30.563473 11879 net.cpp:192] fc8-ucf_fc8-ucf_0_split needs backward computation.
I0429 19:35:30.563480 11879 net.cpp:192] fc8-ucf needs backward computation.
I0429 19:35:30.563488 11879 net.cpp:192] drop7 needs backward computation.
I0429 19:35:30.563493 11879 net.cpp:192] relu7 needs backward computation.
I0429 19:35:30.563500 11879 net.cpp:192] fc7 needs backward computation.
I0429 19:35:30.563506 11879 net.cpp:192] drop6 needs backward computation.
I0429 19:35:30.563513 11879 net.cpp:192] relu6 needs backward computation.
I0429 19:35:30.563519 11879 net.cpp:192] fc6 needs backward computation.
I0429 19:35:30.563525 11879 net.cpp:192] pool5 needs backward computation.
I0429 19:35:30.563534 11879 net.cpp:192] relu5 needs backward computation.
I0429 19:35:30.563539 11879 net.cpp:192] conv5 needs backward computation.
I0429 19:35:30.563546 11879 net.cpp:192] relu4 needs backward computation.
I0429 19:35:30.563554 11879 net.cpp:192] conv4 needs backward computation.
I0429 19:35:30.563560 11879 net.cpp:192] relu3 needs backward computation.
I0429 19:35:30.563567 11879 net.cpp:192] conv3 needs backward computation.
I0429 19:35:30.563575 11879 net.cpp:192] norm2 needs backward computation.
I0429 19:35:30.563581 11879 net.cpp:192] pool2 needs backward computation.
I0429 19:35:30.563588 11879 net.cpp:192] relu2 needs backward computation.
I0429 19:35:30.563594 11879 net.cpp:192] conv2 needs backward computation.
I0429 19:35:30.563601 11879 net.cpp:192] norm1 needs backward computation.
I0429 19:35:30.563607 11879 net.cpp:192] pool1 needs backward computation.
I0429 19:35:30.563614 11879 net.cpp:192] relu1 needs backward computation.
I0429 19:35:30.563621 11879 net.cpp:192] conv1 needs backward computation.
I0429 19:35:30.563628 11879 net.cpp:194] label_data_1_split does not need backward computation.
I0429 19:35:30.563640 11879 net.cpp:194] data does not need backward computation.
I0429 19:35:30.563647 11879 net.cpp:235] This network produces output accuracy
I0429 19:35:30.563654 11879 net.cpp:235] This network produces output loss
I0429 19:35:30.563684 11879 net.cpp:482] Collecting Learning Rate and Weight Decay.
I0429 19:35:30.563697 11879 net.cpp:247] Network initialization done.
I0429 19:35:30.563704 11879 net.cpp:248] Memory required for data: 542230152
I0429 19:35:30.564757 11879 solver.cpp:154] Creating test net (#0) specified by net file: Acre/ac_train_test.prototxt
I0429 19:35:30.564826 11879 net.cpp:287] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0429 19:35:30.565186 11879 net.cpp:42] Initializing net from parameters: 
name: "ac_re"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 103.939
  }
  data_param {
    source: "Acre/Acre_test_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 7
    group: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 5
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-ucf"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8-ucf"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8-ucf"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8-ucf"
  bottom: "label"
  top: "accuracy"
}
I0429 19:35:30.565382 11879 layer_factory.hpp:74] Creating layer data
I0429 19:35:30.565410 11879 net.cpp:90] Creating Layer data
I0429 19:35:30.565421 11879 net.cpp:368] data -> data
I0429 19:35:30.565436 11879 net.cpp:368] data -> label
I0429 19:35:30.565448 11879 net.cpp:120] Setting up data
I0429 19:35:30.581334 11879 db_lmdb.cpp:22] Opened lmdb Acre/Acre_test_lmdb
I0429 19:35:30.582767 11879 data_layer.cpp:52] output data size: 64,12,227,227
I0429 19:35:30.712388 11879 net.cpp:127] Top shape: 64 12 227 227 (39574272)
I0429 19:35:30.712447 11879 net.cpp:127] Top shape: 64 (64)
I0429 19:35:30.712465 11879 layer_factory.hpp:74] Creating layer label_data_1_split
I0429 19:35:30.712492 11879 net.cpp:90] Creating Layer label_data_1_split
I0429 19:35:30.712503 11879 net.cpp:410] label_data_1_split <- label
I0429 19:35:30.712523 11879 net.cpp:368] label_data_1_split -> label_data_1_split_0
I0429 19:35:30.712558 11879 net.cpp:368] label_data_1_split -> label_data_1_split_1
I0429 19:35:30.712570 11879 net.cpp:120] Setting up label_data_1_split
I0429 19:35:30.712589 11879 net.cpp:127] Top shape: 64 (64)
I0429 19:35:30.712597 11879 net.cpp:127] Top shape: 64 (64)
I0429 19:35:30.712605 11879 layer_factory.hpp:74] Creating layer conv1
I0429 19:35:30.712632 11879 net.cpp:90] Creating Layer conv1
I0429 19:35:30.712641 11879 net.cpp:410] conv1 <- data
I0429 19:35:30.712651 11879 net.cpp:368] conv1 -> conv1
I0429 19:35:30.712666 11879 net.cpp:120] Setting up conv1
I0429 19:35:30.721351 11879 net.cpp:127] Top shape: 64 96 109 109 (72996864)
I0429 19:35:30.721410 11879 layer_factory.hpp:74] Creating layer relu1
I0429 19:35:30.721433 11879 net.cpp:90] Creating Layer relu1
I0429 19:35:30.721444 11879 net.cpp:410] relu1 <- conv1
I0429 19:35:30.721462 11879 net.cpp:357] relu1 -> conv1 (in-place)
I0429 19:35:30.721479 11879 net.cpp:120] Setting up relu1
I0429 19:35:30.721597 11879 net.cpp:127] Top shape: 64 96 109 109 (72996864)
I0429 19:35:30.721611 11879 layer_factory.hpp:74] Creating layer pool1
I0429 19:35:30.721626 11879 net.cpp:90] Creating Layer pool1
I0429 19:35:30.721632 11879 net.cpp:410] pool1 <- conv1
I0429 19:35:30.721643 11879 net.cpp:368] pool1 -> pool1
I0429 19:35:30.721655 11879 net.cpp:120] Setting up pool1
I0429 19:35:30.721781 11879 net.cpp:127] Top shape: 64 96 54 54 (17915904)
I0429 19:35:30.721793 11879 layer_factory.hpp:74] Creating layer norm1
I0429 19:35:30.721812 11879 net.cpp:90] Creating Layer norm1
I0429 19:35:30.721820 11879 net.cpp:410] norm1 <- pool1
I0429 19:35:30.721830 11879 net.cpp:368] norm1 -> norm1
I0429 19:35:30.721844 11879 net.cpp:120] Setting up norm1
I0429 19:35:30.721858 11879 net.cpp:127] Top shape: 64 96 54 54 (17915904)
I0429 19:35:30.721866 11879 layer_factory.hpp:74] Creating layer conv2
I0429 19:35:30.721884 11879 net.cpp:90] Creating Layer conv2
I0429 19:35:30.721890 11879 net.cpp:410] conv2 <- norm1
I0429 19:35:30.721901 11879 net.cpp:368] conv2 -> conv2
I0429 19:35:30.721914 11879 net.cpp:120] Setting up conv2
I0429 19:35:30.774525 11879 net.cpp:127] Top shape: 64 384 24 24 (14155776)
I0429 19:35:30.774565 11879 layer_factory.hpp:74] Creating layer relu2
I0429 19:35:30.774581 11879 net.cpp:90] Creating Layer relu2
I0429 19:35:30.774590 11879 net.cpp:410] relu2 <- conv2
I0429 19:35:30.774602 11879 net.cpp:357] relu2 -> conv2 (in-place)
I0429 19:35:30.774616 11879 net.cpp:120] Setting up relu2
I0429 19:35:30.774919 11879 net.cpp:127] Top shape: 64 384 24 24 (14155776)
I0429 19:35:30.774932 11879 layer_factory.hpp:74] Creating layer pool2
I0429 19:35:30.774948 11879 net.cpp:90] Creating Layer pool2
I0429 19:35:30.774955 11879 net.cpp:410] pool2 <- conv2
I0429 19:35:30.774966 11879 net.cpp:368] pool2 -> pool2
I0429 19:35:30.774981 11879 net.cpp:120] Setting up pool2
I0429 19:35:30.775101 11879 net.cpp:127] Top shape: 64 384 12 12 (3538944)
I0429 19:35:30.775113 11879 layer_factory.hpp:74] Creating layer norm2
I0429 19:35:30.775125 11879 net.cpp:90] Creating Layer norm2
I0429 19:35:30.775132 11879 net.cpp:410] norm2 <- pool2
I0429 19:35:30.775142 11879 net.cpp:368] norm2 -> norm2
I0429 19:35:30.775154 11879 net.cpp:120] Setting up norm2
I0429 19:35:30.775197 11879 net.cpp:127] Top shape: 64 384 12 12 (3538944)
I0429 19:35:30.775204 11879 layer_factory.hpp:74] Creating layer conv3
I0429 19:35:30.775218 11879 net.cpp:90] Creating Layer conv3
I0429 19:35:30.775225 11879 net.cpp:410] conv3 <- norm2
I0429 19:35:30.775235 11879 net.cpp:368] conv3 -> conv3
I0429 19:35:30.775249 11879 net.cpp:120] Setting up conv3
I0429 19:35:31.055279 11879 net.cpp:127] Top shape: 64 512 10 10 (3276800)
I0429 19:35:31.055316 11879 layer_factory.hpp:74] Creating layer relu3
I0429 19:35:31.055332 11879 net.cpp:90] Creating Layer relu3
I0429 19:35:31.055341 11879 net.cpp:410] relu3 <- conv3
I0429 19:35:31.055353 11879 net.cpp:357] relu3 -> conv3 (in-place)
I0429 19:35:31.055366 11879 net.cpp:120] Setting up relu3
I0429 19:35:31.055480 11879 net.cpp:127] Top shape: 64 512 10 10 (3276800)
I0429 19:35:31.055492 11879 layer_factory.hpp:74] Creating layer conv4
I0429 19:35:31.055506 11879 net.cpp:90] Creating Layer conv4
I0429 19:35:31.055513 11879 net.cpp:410] conv4 <- conv3
I0429 19:35:31.055524 11879 net.cpp:368] conv4 -> conv4
I0429 19:35:31.055536 11879 net.cpp:120] Setting up conv4
I0429 19:35:31.241175 11879 net.cpp:127] Top shape: 64 512 8 8 (2097152)
I0429 19:35:31.241210 11879 layer_factory.hpp:74] Creating layer relu4
I0429 19:35:31.241226 11879 net.cpp:90] Creating Layer relu4
I0429 19:35:31.241235 11879 net.cpp:410] relu4 <- conv4
I0429 19:35:31.241247 11879 net.cpp:357] relu4 -> conv4 (in-place)
I0429 19:35:31.241261 11879 net.cpp:120] Setting up relu4
I0429 19:35:31.241560 11879 net.cpp:127] Top shape: 64 512 8 8 (2097152)
I0429 19:35:31.241575 11879 layer_factory.hpp:74] Creating layer conv5
I0429 19:35:31.241590 11879 net.cpp:90] Creating Layer conv5
I0429 19:35:31.241596 11879 net.cpp:410] conv5 <- conv4
I0429 19:35:31.241608 11879 net.cpp:368] conv5 -> conv5
I0429 19:35:31.241621 11879 net.cpp:120] Setting up conv5
I0429 19:35:31.292996 11879 net.cpp:127] Top shape: 64 384 8 8 (1572864)
I0429 19:35:31.293036 11879 layer_factory.hpp:74] Creating layer relu5
I0429 19:35:31.293051 11879 net.cpp:90] Creating Layer relu5
I0429 19:35:31.293061 11879 net.cpp:410] relu5 <- conv5
I0429 19:35:31.293072 11879 net.cpp:357] relu5 -> conv5 (in-place)
I0429 19:35:31.293084 11879 net.cpp:120] Setting up relu5
I0429 19:35:31.293197 11879 net.cpp:127] Top shape: 64 384 8 8 (1572864)
I0429 19:35:31.293210 11879 layer_factory.hpp:74] Creating layer pool5
I0429 19:35:31.293226 11879 net.cpp:90] Creating Layer pool5
I0429 19:35:31.293232 11879 net.cpp:410] pool5 <- conv5
I0429 19:35:31.293242 11879 net.cpp:368] pool5 -> pool5
I0429 19:35:31.293254 11879 net.cpp:120] Setting up pool5
I0429 19:35:31.293371 11879 net.cpp:127] Top shape: 64 384 4 4 (393216)
I0429 19:35:31.293383 11879 layer_factory.hpp:74] Creating layer fc6
I0429 19:35:31.293396 11879 net.cpp:90] Creating Layer fc6
I0429 19:35:31.293403 11879 net.cpp:410] fc6 <- pool5
I0429 19:35:31.293414 11879 net.cpp:368] fc6 -> fc6
I0429 19:35:31.293426 11879 net.cpp:120] Setting up fc6
I0429 19:35:31.338204 11879 net.cpp:127] Top shape: 64 128 (8192)
I0429 19:35:31.338230 11879 layer_factory.hpp:74] Creating layer relu6
I0429 19:35:31.338243 11879 net.cpp:90] Creating Layer relu6
I0429 19:35:31.338251 11879 net.cpp:410] relu6 <- fc6
I0429 19:35:31.338263 11879 net.cpp:357] relu6 -> fc6 (in-place)
I0429 19:35:31.338274 11879 net.cpp:120] Setting up relu6
I0429 19:35:31.338400 11879 net.cpp:127] Top shape: 64 128 (8192)
I0429 19:35:31.338412 11879 layer_factory.hpp:74] Creating layer drop6
I0429 19:35:31.338423 11879 net.cpp:90] Creating Layer drop6
I0429 19:35:31.338429 11879 net.cpp:410] drop6 <- fc6
I0429 19:35:31.338439 11879 net.cpp:357] drop6 -> fc6 (in-place)
I0429 19:35:31.338449 11879 net.cpp:120] Setting up drop6
I0429 19:35:31.338461 11879 net.cpp:127] Top shape: 64 128 (8192)
I0429 19:35:31.338469 11879 layer_factory.hpp:74] Creating layer fc7
I0429 19:35:31.338480 11879 net.cpp:90] Creating Layer fc7
I0429 19:35:31.338487 11879 net.cpp:410] fc7 <- fc6
I0429 19:35:31.338497 11879 net.cpp:368] fc7 -> fc7
I0429 19:35:31.338536 11879 net.cpp:120] Setting up fc7
I0429 19:35:31.339010 11879 net.cpp:127] Top shape: 64 64 (4096)
I0429 19:35:31.339025 11879 layer_factory.hpp:74] Creating layer relu7
I0429 19:35:31.339035 11879 net.cpp:90] Creating Layer relu7
I0429 19:35:31.339041 11879 net.cpp:410] relu7 <- fc7
I0429 19:35:31.339051 11879 net.cpp:357] relu7 -> fc7 (in-place)
I0429 19:35:31.339061 11879 net.cpp:120] Setting up relu7
I0429 19:35:31.339406 11879 net.cpp:127] Top shape: 64 64 (4096)
I0429 19:35:31.339421 11879 layer_factory.hpp:74] Creating layer drop7
I0429 19:35:31.339432 11879 net.cpp:90] Creating Layer drop7
I0429 19:35:31.339439 11879 net.cpp:410] drop7 <- fc7
I0429 19:35:31.339448 11879 net.cpp:357] drop7 -> fc7 (in-place)
I0429 19:35:31.339459 11879 net.cpp:120] Setting up drop7
I0429 19:35:31.339470 11879 net.cpp:127] Top shape: 64 64 (4096)
I0429 19:35:31.339478 11879 layer_factory.hpp:74] Creating layer fc8-ucf
I0429 19:35:31.339489 11879 net.cpp:90] Creating Layer fc8-ucf
I0429 19:35:31.339496 11879 net.cpp:410] fc8-ucf <- fc7
I0429 19:35:31.339506 11879 net.cpp:368] fc8-ucf -> fc8-ucf
I0429 19:35:31.339521 11879 net.cpp:120] Setting up fc8-ucf
I0429 19:35:31.339576 11879 net.cpp:127] Top shape: 64 10 (640)
I0429 19:35:31.339591 11879 layer_factory.hpp:74] Creating layer fc8-ucf_fc8-ucf_0_split
I0429 19:35:31.339601 11879 net.cpp:90] Creating Layer fc8-ucf_fc8-ucf_0_split
I0429 19:35:31.339608 11879 net.cpp:410] fc8-ucf_fc8-ucf_0_split <- fc8-ucf
I0429 19:35:31.339618 11879 net.cpp:368] fc8-ucf_fc8-ucf_0_split -> fc8-ucf_fc8-ucf_0_split_0
I0429 19:35:31.339629 11879 net.cpp:368] fc8-ucf_fc8-ucf_0_split -> fc8-ucf_fc8-ucf_0_split_1
I0429 19:35:31.339639 11879 net.cpp:120] Setting up fc8-ucf_fc8-ucf_0_split
I0429 19:35:31.339651 11879 net.cpp:127] Top shape: 64 10 (640)
I0429 19:35:31.339660 11879 net.cpp:127] Top shape: 64 10 (640)
I0429 19:35:31.339666 11879 layer_factory.hpp:74] Creating layer loss
I0429 19:35:31.339676 11879 net.cpp:90] Creating Layer loss
I0429 19:35:31.339684 11879 net.cpp:410] loss <- fc8-ucf_fc8-ucf_0_split_0
I0429 19:35:31.339691 11879 net.cpp:410] loss <- label_data_1_split_0
I0429 19:35:31.339700 11879 net.cpp:368] loss -> loss
I0429 19:35:31.339711 11879 net.cpp:120] Setting up loss
I0429 19:35:31.339721 11879 layer_factory.hpp:74] Creating layer loss
I0429 19:35:31.339848 11879 net.cpp:127] Top shape: (1)
I0429 19:35:31.339859 11879 net.cpp:129]     with loss weight 1
I0429 19:35:31.339877 11879 layer_factory.hpp:74] Creating layer accuracy
I0429 19:35:31.339887 11879 net.cpp:90] Creating Layer accuracy
I0429 19:35:31.339895 11879 net.cpp:410] accuracy <- fc8-ucf_fc8-ucf_0_split_1
I0429 19:35:31.339903 11879 net.cpp:410] accuracy <- label_data_1_split_1
I0429 19:35:31.339912 11879 net.cpp:368] accuracy -> accuracy
I0429 19:35:31.339922 11879 net.cpp:120] Setting up accuracy
I0429 19:35:31.339933 11879 net.cpp:127] Top shape: (1)
I0429 19:35:31.339941 11879 net.cpp:194] accuracy does not need backward computation.
I0429 19:35:31.339948 11879 net.cpp:192] loss needs backward computation.
I0429 19:35:31.339956 11879 net.cpp:192] fc8-ucf_fc8-ucf_0_split needs backward computation.
I0429 19:35:31.339963 11879 net.cpp:192] fc8-ucf needs backward computation.
I0429 19:35:31.339970 11879 net.cpp:192] drop7 needs backward computation.
I0429 19:35:31.339977 11879 net.cpp:192] relu7 needs backward computation.
I0429 19:35:31.339983 11879 net.cpp:192] fc7 needs backward computation.
I0429 19:35:31.339989 11879 net.cpp:192] drop6 needs backward computation.
I0429 19:35:31.339996 11879 net.cpp:192] relu6 needs backward computation.
I0429 19:35:31.340003 11879 net.cpp:192] fc6 needs backward computation.
I0429 19:35:31.340009 11879 net.cpp:192] pool5 needs backward computation.
I0429 19:35:31.340015 11879 net.cpp:192] relu5 needs backward computation.
I0429 19:35:31.340023 11879 net.cpp:192] conv5 needs backward computation.
I0429 19:35:31.340029 11879 net.cpp:192] relu4 needs backward computation.
I0429 19:35:31.340035 11879 net.cpp:192] conv4 needs backward computation.
I0429 19:35:31.340042 11879 net.cpp:192] relu3 needs backward computation.
I0429 19:35:31.340068 11879 net.cpp:192] conv3 needs backward computation.
I0429 19:35:31.340076 11879 net.cpp:192] norm2 needs backward computation.
I0429 19:35:31.340083 11879 net.cpp:192] pool2 needs backward computation.
I0429 19:35:31.340090 11879 net.cpp:192] relu2 needs backward computation.
I0429 19:35:31.340101 11879 net.cpp:192] conv2 needs backward computation.
I0429 19:35:31.340111 11879 net.cpp:192] norm1 needs backward computation.
I0429 19:35:31.340117 11879 net.cpp:192] pool1 needs backward computation.
I0429 19:35:31.340123 11879 net.cpp:192] relu1 needs backward computation.
I0429 19:35:31.340131 11879 net.cpp:192] conv1 needs backward computation.
I0429 19:35:31.340138 11879 net.cpp:194] label_data_1_split does not need backward computation.
I0429 19:35:31.340147 11879 net.cpp:194] data does not need backward computation.
I0429 19:35:31.340152 11879 net.cpp:235] This network produces output accuracy
I0429 19:35:31.340159 11879 net.cpp:235] This network produces output loss
I0429 19:35:31.340184 11879 net.cpp:482] Collecting Learning Rate and Weight Decay.
I0429 19:35:31.340198 11879 net.cpp:247] Network initialization done.
I0429 19:35:31.340204 11879 net.cpp:248] Memory required for data: 1084460296
I0429 19:35:31.340332 11879 solver.cpp:42] Solver scaffolding done.
I0429 19:35:31.340392 11879 solver.cpp:250] Solving ac_re
I0429 19:35:31.340399 11879 solver.cpp:251] Learning Rate Policy: step
I0429 19:35:31.342594 11879 solver.cpp:294] Iteration 0, Testing net (#0)
I0429 19:37:16.090126 11879 solver.cpp:343]     Test net output #0: accuracy = 0.117812
I0429 19:37:16.103905 11879 solver.cpp:343]     Test net output #1: loss = 2.30194 (* 1 = 2.30194 loss)
I0429 19:37:17.071207 11879 solver.cpp:214] Iteration 0, loss = 2.30081
I0429 19:37:17.071249 11879 solver.cpp:229]     Train net output #0: accuracy = 0.15625
I0429 19:37:17.071269 11879 solver.cpp:229]     Train net output #1: loss = 2.30081 (* 1 = 2.30081 loss)
I0429 19:37:17.071297 11879 solver.cpp:486] Iteration 0, lr = 0.005
I0429 19:37:40.979022 11879 solver.cpp:214] Iteration 20, loss = 2.30914
I0429 19:37:40.979063 11879 solver.cpp:229]     Train net output #0: accuracy = 0.0625
I0429 19:37:40.979084 11879 solver.cpp:229]     Train net output #1: loss = 2.30914 (* 1 = 2.30914 loss)
I0429 19:37:40.979096 11879 solver.cpp:486] Iteration 20, lr = 0.005
I0429 19:38:04.343171 11879 solver.cpp:214] Iteration 40, loss = 2.32655
I0429 19:38:04.343272 11879 solver.cpp:229]     Train net output #0: accuracy = 0.0625
I0429 19:38:04.343291 11879 solver.cpp:229]     Train net output #1: loss = 2.32655 (* 1 = 2.32655 loss)
I0429 19:38:04.343300 11879 solver.cpp:486] Iteration 40, lr = 0.005
I0429 19:38:26.141618 11879 solver.cpp:214] Iteration 60, loss = 2.34591
I0429 19:38:26.141651 11879 solver.cpp:229]     Train net output #0: accuracy = 0.03125
I0429 19:38:26.141665 11879 solver.cpp:229]     Train net output #1: loss = 2.34591 (* 1 = 2.34591 loss)
I0429 19:38:26.141674 11879 solver.cpp:486] Iteration 60, lr = 0.005
I0429 19:38:48.089835 11879 solver.cpp:214] Iteration 80, loss = 2.19443
I0429 19:38:48.090065 11879 solver.cpp:229]     Train net output #0: accuracy = 0.25
I0429 19:38:48.090095 11879 solver.cpp:229]     Train net output #1: loss = 2.19443 (* 1 = 2.19443 loss)
I0429 19:38:48.090111 11879 solver.cpp:486] Iteration 80, lr = 0.005
I0429 19:39:08.961671 11879 solver.cpp:214] Iteration 100, loss = 2.15176
I0429 19:39:08.961711 11879 solver.cpp:229]     Train net output #0: accuracy = 0.21875
I0429 19:39:08.961724 11879 solver.cpp:229]     Train net output #1: loss = 2.15176 (* 1 = 2.15176 loss)
I0429 19:39:08.961733 11879 solver.cpp:486] Iteration 100, lr = 0.005
I0429 19:39:30.228440 11879 solver.cpp:214] Iteration 120, loss = 2.18822
I0429 19:39:30.228610 11879 solver.cpp:229]     Train net output #0: accuracy = 0.15625
I0429 19:39:30.228634 11879 solver.cpp:229]     Train net output #1: loss = 2.18822 (* 1 = 2.18822 loss)
I0429 19:39:30.228654 11879 solver.cpp:486] Iteration 120, lr = 0.005
I0429 19:39:51.442625 11879 solver.cpp:214] Iteration 140, loss = 2.09115
I0429 19:39:51.442667 11879 solver.cpp:229]     Train net output #0: accuracy = 0.09375
I0429 19:39:51.442694 11879 solver.cpp:229]     Train net output #1: loss = 2.09115 (* 1 = 2.09115 loss)
I0429 19:39:51.442709 11879 solver.cpp:486] Iteration 140, lr = 0.005
I0429 19:40:12.510352 11879 solver.cpp:214] Iteration 160, loss = 1.98173
I0429 19:40:12.510511 11879 solver.cpp:229]     Train net output #0: accuracy = 0.3125
I0429 19:40:12.510537 11879 solver.cpp:229]     Train net output #1: loss = 1.98173 (* 1 = 1.98173 loss)
I0429 19:40:12.510550 11879 solver.cpp:486] Iteration 160, lr = 0.005
I0429 19:40:33.326906 11879 solver.cpp:214] Iteration 180, loss = 2.20604
I0429 19:40:33.326947 11879 solver.cpp:229]     Train net output #0: accuracy = 0.25
I0429 19:40:33.326967 11879 solver.cpp:229]     Train net output #1: loss = 2.20604 (* 1 = 2.20604 loss)
I0429 19:40:33.326982 11879 solver.cpp:486] Iteration 180, lr = 0.005
I0429 19:40:54.156755 11879 solver.cpp:294] Iteration 200, Testing net (#0)
I0429 19:43:51.889722 11879 solver.cpp:343]     Test net output #0: accuracy = 0.362188
I0429 19:43:51.889896 11879 solver.cpp:343]     Test net output #1: loss = 1.90404 (* 1 = 1.90404 loss)
I0429 19:43:52.159708 11879 solver.cpp:214] Iteration 200, loss = 1.84446
I0429 19:43:52.159742 11879 solver.cpp:229]     Train net output #0: accuracy = 0.375
I0429 19:43:52.159754 11879 solver.cpp:229]     Train net output #1: loss = 1.84446 (* 1 = 1.84446 loss)
I0429 19:43:52.159764 11879 solver.cpp:486] Iteration 200, lr = 0.005
I0429 19:44:15.432128 11879 solver.cpp:214] Iteration 220, loss = 1.8343
I0429 19:44:15.432166 11879 solver.cpp:229]     Train net output #0: accuracy = 0.25
I0429 19:44:15.432185 11879 solver.cpp:229]     Train net output #1: loss = 1.8343 (* 1 = 1.8343 loss)
I0429 19:44:15.432198 11879 solver.cpp:486] Iteration 220, lr = 0.005
I0429 19:44:36.506716 11879 solver.cpp:214] Iteration 240, loss = 1.98484
I0429 19:44:36.506885 11879 solver.cpp:229]     Train net output #0: accuracy = 0.34375
I0429 19:44:36.506907 11879 solver.cpp:229]     Train net output #1: loss = 1.98484 (* 1 = 1.98484 loss)
I0429 19:44:36.506922 11879 solver.cpp:486] Iteration 240, lr = 0.005
I0429 19:44:57.218600 11879 solver.cpp:214] Iteration 260, loss = 1.75227
I0429 19:44:57.218641 11879 solver.cpp:229]     Train net output #0: accuracy = 0.375
I0429 19:44:57.218654 11879 solver.cpp:229]     Train net output #1: loss = 1.75227 (* 1 = 1.75227 loss)
I0429 19:44:57.218663 11879 solver.cpp:486] Iteration 260, lr = 0.005
I0429 19:45:17.915637 11879 solver.cpp:214] Iteration 280, loss = 2.02012
I0429 19:45:17.915781 11879 solver.cpp:229]     Train net output #0: accuracy = 0.3125
I0429 19:45:17.915818 11879 solver.cpp:229]     Train net output #1: loss = 2.02012 (* 1 = 2.02012 loss)
I0429 19:45:17.915839 11879 solver.cpp:486] Iteration 280, lr = 0.005
I0429 19:45:38.493167 11879 solver.cpp:214] Iteration 300, loss = 1.59632
I0429 19:45:38.493248 11879 solver.cpp:229]     Train net output #0: accuracy = 0.3125
I0429 19:45:38.493275 11879 solver.cpp:229]     Train net output #1: loss = 1.59632 (* 1 = 1.59632 loss)
I0429 19:45:38.493296 11879 solver.cpp:486] Iteration 300, lr = 0.005
I0429 19:46:29.209416 11879 solver.cpp:214] Iteration 320, loss = 1.66633
I0429 19:46:29.209631 11879 solver.cpp:229]     Train net output #0: accuracy = 0.46875
I0429 19:46:29.209666 11879 solver.cpp:229]     Train net output #1: loss = 1.66633 (* 1 = 1.66633 loss)
I0429 19:46:29.209687 11879 solver.cpp:486] Iteration 320, lr = 0.005
I0429 19:47:11.918270 11879 solver.cpp:214] Iteration 340, loss = 1.8428
I0429 19:47:11.918517 11879 solver.cpp:229]     Train net output #0: accuracy = 0.34375
I0429 19:47:11.918543 11879 solver.cpp:229]     Train net output #1: loss = 1.8428 (* 1 = 1.8428 loss)
I0429 19:47:11.918561 11879 solver.cpp:486] Iteration 340, lr = 0.005
I0429 19:47:33.675571 11879 solver.cpp:214] Iteration 360, loss = 1.48392
I0429 19:47:33.675612 11879 solver.cpp:229]     Train net output #0: accuracy = 0.4375
I0429 19:47:33.675626 11879 solver.cpp:229]     Train net output #1: loss = 1.48392 (* 1 = 1.48392 loss)
I0429 19:47:33.675634 11879 solver.cpp:486] Iteration 360, lr = 0.005
I0429 19:47:55.464263 11879 solver.cpp:214] Iteration 380, loss = 1.52889
I0429 19:47:55.464454 11879 solver.cpp:229]     Train net output #0: accuracy = 0.40625
I0429 19:47:55.464478 11879 solver.cpp:229]     Train net output #1: loss = 1.52889 (* 1 = 1.52889 loss)
I0429 19:47:55.464490 11879 solver.cpp:486] Iteration 380, lr = 0.005
I0429 19:48:14.990490 11879 solver.cpp:294] Iteration 400, Testing net (#0)
I0429 19:51:11.283419 11879 solver.cpp:343]     Test net output #0: accuracy = 0.382031
I0429 19:51:11.321606 11879 solver.cpp:343]     Test net output #1: loss = 1.74981 (* 1 = 1.74981 loss)
I0429 19:51:11.598719 11879 solver.cpp:214] Iteration 400, loss = 1.74253
I0429 19:51:11.598763 11879 solver.cpp:229]     Train net output #0: accuracy = 0.34375
I0429 19:51:11.598783 11879 solver.cpp:229]     Train net output #1: loss = 1.74253 (* 1 = 1.74253 loss)
I0429 19:51:11.598796 11879 solver.cpp:486] Iteration 400, lr = 0.005
I0429 19:51:35.397497 11879 solver.cpp:214] Iteration 420, loss = 1.35434
I0429 19:51:35.397536 11879 solver.cpp:229]     Train net output #0: accuracy = 0.5
I0429 19:51:35.397549 11879 solver.cpp:229]     Train net output #1: loss = 1.35434 (* 1 = 1.35434 loss)
I0429 19:51:35.397558 11879 solver.cpp:486] Iteration 420, lr = 0.005
I0429 19:52:10.242518 11879 solver.cpp:214] Iteration 440, loss = 1.52036
I0429 19:52:10.242733 11879 solver.cpp:229]     Train net output #0: accuracy = 0.40625
I0429 19:52:10.242756 11879 solver.cpp:229]     Train net output #1: loss = 1.52036 (* 1 = 1.52036 loss)
I0429 19:52:10.242769 11879 solver.cpp:486] Iteration 440, lr = 0.005
I0429 19:52:35.596869 11879 solver.cpp:214] Iteration 460, loss = 1.85875
I0429 19:52:35.596938 11879 solver.cpp:229]     Train net output #0: accuracy = 0.21875
I0429 19:52:35.596952 11879 solver.cpp:229]     Train net output #1: loss = 1.85875 (* 1 = 1.85875 loss)
I0429 19:52:35.596961 11879 solver.cpp:486] Iteration 460, lr = 0.005
I0429 19:53:28.589390 11879 solver.cpp:214] Iteration 480, loss = 1.4785
I0429 19:53:28.589555 11879 solver.cpp:229]     Train net output #0: accuracy = 0.46875
I0429 19:53:28.589578 11879 solver.cpp:229]     Train net output #1: loss = 1.4785 (* 1 = 1.4785 loss)
I0429 19:53:28.589592 11879 solver.cpp:486] Iteration 480, lr = 0.005
I0429 19:54:05.392957 11879 solver.cpp:214] Iteration 500, loss = 1.40433
I0429 19:54:05.393182 11879 solver.cpp:229]     Train net output #0: accuracy = 0.5625
I0429 19:54:05.393205 11879 solver.cpp:229]     Train net output #1: loss = 1.40433 (* 1 = 1.40433 loss)
I0429 19:54:05.393219 11879 solver.cpp:486] Iteration 500, lr = 0.005
I0429 19:54:25.982503 11879 solver.cpp:214] Iteration 520, loss = 1.50601
I0429 19:54:25.982543 11879 solver.cpp:229]     Train net output #0: accuracy = 0.34375
I0429 19:54:25.982556 11879 solver.cpp:229]     Train net output #1: loss = 1.50601 (* 1 = 1.50601 loss)
I0429 19:54:25.982565 11879 solver.cpp:486] Iteration 520, lr = 0.005
I0429 19:54:47.360832 11879 solver.cpp:214] Iteration 540, loss = 1.43451
I0429 19:54:47.360926 11879 solver.cpp:229]     Train net output #0: accuracy = 0.5625
I0429 19:54:47.360951 11879 solver.cpp:229]     Train net output #1: loss = 1.43451 (* 1 = 1.43451 loss)
I0429 19:54:47.360970 11879 solver.cpp:486] Iteration 540, lr = 0.005
I0429 19:55:09.225105 11879 solver.cpp:214] Iteration 560, loss = 1.13777
I0429 19:55:09.225144 11879 solver.cpp:229]     Train net output #0: accuracy = 0.53125
I0429 19:55:09.225158 11879 solver.cpp:229]     Train net output #1: loss = 1.13777 (* 1 = 1.13777 loss)
I0429 19:55:09.225167 11879 solver.cpp:486] Iteration 560, lr = 0.005
I0429 19:55:30.482939 11879 solver.cpp:214] Iteration 580, loss = 1.11592
I0429 19:55:30.483105 11879 solver.cpp:229]     Train net output #0: accuracy = 0.59375
I0429 19:55:30.483130 11879 solver.cpp:229]     Train net output #1: loss = 1.11592 (* 1 = 1.11592 loss)
I0429 19:55:30.483144 11879 solver.cpp:486] Iteration 580, lr = 0.005
I0429 19:55:50.730512 11879 solver.cpp:294] Iteration 600, Testing net (#0)
I0429 19:58:00.224010 11879 solver.cpp:343]     Test net output #0: accuracy = 0.400156
I0429 19:58:00.230818 11879 solver.cpp:343]     Test net output #1: loss = 1.54361 (* 1 = 1.54361 loss)
I0429 19:58:00.514482 11879 solver.cpp:214] Iteration 600, loss = 1.15823
I0429 19:58:00.514520 11879 solver.cpp:229]     Train net output #0: accuracy = 0.6875
I0429 19:58:00.514533 11879 solver.cpp:229]     Train net output #1: loss = 1.15823 (* 1 = 1.15823 loss)
I0429 19:58:00.514542 11879 solver.cpp:486] Iteration 600, lr = 0.005
I0429 19:58:22.809283 11879 solver.cpp:214] Iteration 620, loss = 1.58965
I0429 19:58:22.809325 11879 solver.cpp:229]     Train net output #0: accuracy = 0.34375
I0429 19:58:22.809345 11879 solver.cpp:229]     Train net output #1: loss = 1.58965 (* 1 = 1.58965 loss)
I0429 19:58:22.809360 11879 solver.cpp:486] Iteration 620, lr = 0.005
I0429 19:58:44.098839 11879 solver.cpp:214] Iteration 640, loss = 1.56673
I0429 19:58:44.098968 11879 solver.cpp:229]     Train net output #0: accuracy = 0.40625
I0429 19:58:44.099021 11879 solver.cpp:229]     Train net output #1: loss = 1.56673 (* 1 = 1.56673 loss)
I0429 19:58:44.099061 11879 solver.cpp:486] Iteration 640, lr = 0.005
I0429 19:59:06.465651 11879 solver.cpp:214] Iteration 660, loss = 1.32182
I0429 19:59:06.465687 11879 solver.cpp:229]     Train net output #0: accuracy = 0.40625
I0429 19:59:06.465700 11879 solver.cpp:229]     Train net output #1: loss = 1.32182 (* 1 = 1.32182 loss)
I0429 19:59:06.465709 11879 solver.cpp:486] Iteration 660, lr = 0.005
I0429 19:59:27.440784 11879 solver.cpp:214] Iteration 680, loss = 1.05143
I0429 19:59:27.440945 11879 solver.cpp:229]     Train net output #0: accuracy = 0.59375
I0429 19:59:27.440970 11879 solver.cpp:229]     Train net output #1: loss = 1.05143 (* 1 = 1.05143 loss)
I0429 19:59:27.440982 11879 solver.cpp:486] Iteration 680, lr = 0.005
I0429 19:59:48.112197 11879 solver.cpp:214] Iteration 700, loss = 1.12852
I0429 19:59:48.112231 11879 solver.cpp:229]     Train net output #0: accuracy = 0.5625
I0429 19:59:48.112243 11879 solver.cpp:229]     Train net output #1: loss = 1.12852 (* 1 = 1.12852 loss)
I0429 19:59:48.112251 11879 solver.cpp:486] Iteration 700, lr = 0.005
I0429 20:00:09.758374 11879 solver.cpp:214] Iteration 720, loss = 1.3589
I0429 20:00:09.758457 11879 solver.cpp:229]     Train net output #0: accuracy = 0.4375
I0429 20:00:09.758481 11879 solver.cpp:229]     Train net output #1: loss = 1.3589 (* 1 = 1.3589 loss)
I0429 20:00:09.758522 11879 solver.cpp:486] Iteration 720, lr = 0.005
I0429 20:00:30.456143 11879 solver.cpp:214] Iteration 740, loss = 1.08209
I0429 20:00:30.456177 11879 solver.cpp:229]     Train net output #0: accuracy = 0.625
I0429 20:00:30.456190 11879 solver.cpp:229]     Train net output #1: loss = 1.08209 (* 1 = 1.08209 loss)
I0429 20:00:30.456198 11879 solver.cpp:486] Iteration 740, lr = 0.005
I0429 20:00:51.172698 11879 solver.cpp:214] Iteration 760, loss = 1.02891
I0429 20:00:51.172864 11879 solver.cpp:229]     Train net output #0: accuracy = 0.59375
I0429 20:00:51.172888 11879 solver.cpp:229]     Train net output #1: loss = 1.02891 (* 1 = 1.02891 loss)
I0429 20:00:51.172901 11879 solver.cpp:486] Iteration 760, lr = 0.005
I0429 20:01:12.087093 11879 solver.cpp:214] Iteration 780, loss = 1.29423
I0429 20:01:12.087149 11879 solver.cpp:229]     Train net output #0: accuracy = 0.6875
I0429 20:01:12.087179 11879 solver.cpp:229]     Train net output #1: loss = 1.29423 (* 1 = 1.29423 loss)
I0429 20:01:12.087196 11879 solver.cpp:486] Iteration 780, lr = 0.005
I0429 20:01:32.326445 11879 solver.cpp:294] Iteration 800, Testing net (#0)
I0429 20:04:28.663305 11879 solver.cpp:343]     Test net output #0: accuracy = 0.490156
I0429 20:04:28.663400 11879 solver.cpp:343]     Test net output #1: loss = 1.41336 (* 1 = 1.41336 loss)
I0429 20:04:28.984642 11879 solver.cpp:214] Iteration 800, loss = 1.07067
I0429 20:04:28.984680 11879 solver.cpp:229]     Train net output #0: accuracy = 0.59375
I0429 20:04:28.984694 11879 solver.cpp:229]     Train net output #1: loss = 1.07067 (* 1 = 1.07067 loss)
I0429 20:04:28.984702 11879 solver.cpp:486] Iteration 800, lr = 0.005
I0429 20:04:52.327503 11879 solver.cpp:214] Iteration 820, loss = 0.935683
I0429 20:04:52.327546 11879 solver.cpp:229]     Train net output #0: accuracy = 0.59375
I0429 20:04:52.327565 11879 solver.cpp:229]     Train net output #1: loss = 0.935683 (* 1 = 0.935683 loss)
I0429 20:04:52.327579 11879 solver.cpp:486] Iteration 820, lr = 0.005
I0429 20:05:13.428318 11879 solver.cpp:214] Iteration 840, loss = 0.780727
I0429 20:05:13.428424 11879 solver.cpp:229]     Train net output #0: accuracy = 0.65625
I0429 20:05:13.428441 11879 solver.cpp:229]     Train net output #1: loss = 0.780727 (* 1 = 0.780727 loss)
I0429 20:05:13.428450 11879 solver.cpp:486] Iteration 840, lr = 0.005
I0429 20:05:34.864457 11879 solver.cpp:214] Iteration 860, loss = 1.34497
I0429 20:05:34.864519 11879 solver.cpp:229]     Train net output #0: accuracy = 0.5625
I0429 20:05:34.864536 11879 solver.cpp:229]     Train net output #1: loss = 1.34497 (* 1 = 1.34497 loss)
I0429 20:05:34.864544 11879 solver.cpp:486] Iteration 860, lr = 0.005
I0429 20:05:57.250094 11879 solver.cpp:214] Iteration 880, loss = 0.835987
I0429 20:05:57.250221 11879 solver.cpp:229]     Train net output #0: accuracy = 0.6875
I0429 20:05:57.250236 11879 solver.cpp:229]     Train net output #1: loss = 0.835987 (* 1 = 0.835987 loss)
I0429 20:05:57.250247 11879 solver.cpp:486] Iteration 880, lr = 0.005
I0429 20:06:19.454280 11879 solver.cpp:214] Iteration 900, loss = 0.805351
I0429 20:06:19.454345 11879 solver.cpp:229]     Train net output #0: accuracy = 0.6875
I0429 20:06:19.454362 11879 solver.cpp:229]     Train net output #1: loss = 0.805351 (* 1 = 0.805351 loss)
I0429 20:06:19.454375 11879 solver.cpp:486] Iteration 900, lr = 0.005
I0429 20:06:41.396392 11879 solver.cpp:214] Iteration 920, loss = 1.19158
I0429 20:06:41.396555 11879 solver.cpp:229]     Train net output #0: accuracy = 0.5
I0429 20:06:41.396579 11879 solver.cpp:229]     Train net output #1: loss = 1.19158 (* 1 = 1.19158 loss)
I0429 20:06:41.396592 11879 solver.cpp:486] Iteration 920, lr = 0.005
I0429 20:07:02.480877 11879 solver.cpp:214] Iteration 940, loss = 0.958675
I0429 20:07:02.480917 11879 solver.cpp:229]     Train net output #0: accuracy = 0.6875
I0429 20:07:02.480931 11879 solver.cpp:229]     Train net output #1: loss = 0.958675 (* 1 = 0.958675 loss)
I0429 20:07:02.480939 11879 solver.cpp:486] Iteration 940, lr = 0.005
I0429 20:07:24.012677 11879 solver.cpp:214] Iteration 960, loss = 0.861389
I0429 20:07:24.012809 11879 solver.cpp:229]     Train net output #0: accuracy = 0.75
I0429 20:07:24.012861 11879 solver.cpp:229]     Train net output #1: loss = 0.861389 (* 1 = 0.861389 loss)
I0429 20:07:24.012887 11879 solver.cpp:486] Iteration 960, lr = 0.005
I0429 20:07:46.329771 11879 solver.cpp:214] Iteration 980, loss = 0.652841
I0429 20:07:46.329813 11879 solver.cpp:229]     Train net output #0: accuracy = 0.78125
I0429 20:07:46.329833 11879 solver.cpp:229]     Train net output #1: loss = 0.652841 (* 1 = 0.652841 loss)
I0429 20:07:46.329845 11879 solver.cpp:486] Iteration 980, lr = 0.005
I0429 20:08:07.326958 11879 solver.cpp:294] Iteration 1000, Testing net (#0)
I0429 20:11:56.479487 11879 solver.cpp:343]     Test net output #0: accuracy = 0.485938
I0429 20:11:56.479574 11879 solver.cpp:343]     Test net output #1: loss = 1.51767 (* 1 = 1.51767 loss)
I0429 20:11:56.821568 11879 solver.cpp:214] Iteration 1000, loss = 0.901952
I0429 20:11:56.821604 11879 solver.cpp:229]     Train net output #0: accuracy = 0.65625
I0429 20:11:56.821617 11879 solver.cpp:229]     Train net output #1: loss = 0.901952 (* 1 = 0.901952 loss)
I0429 20:11:56.821626 11879 solver.cpp:486] Iteration 1000, lr = 0.005
I0429 20:12:22.502034 11879 solver.cpp:214] Iteration 1020, loss = 1.09187
I0429 20:12:22.502074 11879 solver.cpp:229]     Train net output #0: accuracy = 0.71875
I0429 20:12:22.502086 11879 solver.cpp:229]     Train net output #1: loss = 1.09187 (* 1 = 1.09187 loss)
I0429 20:12:22.502095 11879 solver.cpp:486] Iteration 1020, lr = 0.005
I0429 20:12:45.204619 11879 solver.cpp:214] Iteration 1040, loss = 1.13146
I0429 20:12:45.204870 11879 solver.cpp:229]     Train net output #0: accuracy = 0.625
I0429 20:12:45.204895 11879 solver.cpp:229]     Train net output #1: loss = 1.13146 (* 1 = 1.13146 loss)
I0429 20:12:45.204908 11879 solver.cpp:486] Iteration 1040, lr = 0.005
I0429 20:13:06.309011 11879 solver.cpp:214] Iteration 1060, loss = 0.891151
I0429 20:13:06.309106 11879 solver.cpp:229]     Train net output #0: accuracy = 0.65625
I0429 20:13:06.309123 11879 solver.cpp:229]     Train net output #1: loss = 0.891151 (* 1 = 0.891151 loss)
I0429 20:13:06.309134 11879 solver.cpp:486] Iteration 1060, lr = 0.005
I0429 20:13:27.679904 11879 solver.cpp:214] Iteration 1080, loss = 0.665939
I0429 20:13:27.680022 11879 solver.cpp:229]     Train net output #0: accuracy = 0.71875
I0429 20:13:27.680039 11879 solver.cpp:229]     Train net output #1: loss = 0.665939 (* 1 = 0.665939 loss)
I0429 20:13:27.680053 11879 solver.cpp:486] Iteration 1080, lr = 0.005
I0429 20:13:49.711002 11879 solver.cpp:214] Iteration 1100, loss = 0.853814
I0429 20:13:49.711043 11879 solver.cpp:229]     Train net output #0: accuracy = 0.71875
I0429 20:13:49.711056 11879 solver.cpp:229]     Train net output #1: loss = 0.853813 (* 1 = 0.853813 loss)
I0429 20:13:49.711066 11879 solver.cpp:486] Iteration 1100, lr = 0.005
I0429 20:14:10.608882 11879 solver.cpp:214] Iteration 1120, loss = 0.605637
I0429 20:14:10.609089 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:14:10.609113 11879 solver.cpp:229]     Train net output #1: loss = 0.605636 (* 1 = 0.605636 loss)
I0429 20:14:10.609127 11879 solver.cpp:486] Iteration 1120, lr = 0.005
I0429 20:14:31.376348 11879 solver.cpp:214] Iteration 1140, loss = 1.10098
I0429 20:14:31.376392 11879 solver.cpp:229]     Train net output #0: accuracy = 0.53125
I0429 20:14:31.376406 11879 solver.cpp:229]     Train net output #1: loss = 1.10098 (* 1 = 1.10098 loss)
I0429 20:14:31.376415 11879 solver.cpp:486] Iteration 1140, lr = 0.005
I0429 20:14:53.165197 11879 solver.cpp:214] Iteration 1160, loss = 0.896197
I0429 20:14:53.165333 11879 solver.cpp:229]     Train net output #0: accuracy = 0.65625
I0429 20:14:53.165359 11879 solver.cpp:229]     Train net output #1: loss = 0.896197 (* 1 = 0.896197 loss)
I0429 20:14:53.165371 11879 solver.cpp:486] Iteration 1160, lr = 0.005
I0429 20:15:15.185225 11879 solver.cpp:214] Iteration 1180, loss = 0.793528
I0429 20:15:15.185297 11879 solver.cpp:229]     Train net output #0: accuracy = 0.6875
I0429 20:15:15.185310 11879 solver.cpp:229]     Train net output #1: loss = 0.793528 (* 1 = 0.793528 loss)
I0429 20:15:15.185322 11879 solver.cpp:486] Iteration 1180, lr = 0.005
I0429 20:15:35.194111 11879 solver.cpp:294] Iteration 1200, Testing net (#0)
I0429 20:18:04.425779 11879 solver.cpp:343]     Test net output #0: accuracy = 0.562969
I0429 20:18:04.425866 11879 solver.cpp:343]     Test net output #1: loss = 1.41081 (* 1 = 1.41081 loss)
I0429 20:18:04.797925 11879 solver.cpp:214] Iteration 1200, loss = 0.544607
I0429 20:18:04.797962 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:18:04.797976 11879 solver.cpp:229]     Train net output #1: loss = 0.544607 (* 1 = 0.544607 loss)
I0429 20:18:04.797984 11879 solver.cpp:486] Iteration 1200, lr = 0.005
I0429 20:18:29.241760 11879 solver.cpp:214] Iteration 1220, loss = 1.05047
I0429 20:18:29.241806 11879 solver.cpp:229]     Train net output #0: accuracy = 0.625
I0429 20:18:29.241823 11879 solver.cpp:229]     Train net output #1: loss = 1.05047 (* 1 = 1.05047 loss)
I0429 20:18:29.241835 11879 solver.cpp:486] Iteration 1220, lr = 0.005
I0429 20:18:50.857827 11879 solver.cpp:214] Iteration 1240, loss = 0.937996
I0429 20:18:50.857964 11879 solver.cpp:229]     Train net output #0: accuracy = 0.65625
I0429 20:18:50.857993 11879 solver.cpp:229]     Train net output #1: loss = 0.937996 (* 1 = 0.937996 loss)
I0429 20:18:50.858014 11879 solver.cpp:486] Iteration 1240, lr = 0.005
I0429 20:19:12.819664 11879 solver.cpp:214] Iteration 1260, loss = 0.666331
I0429 20:19:12.819707 11879 solver.cpp:229]     Train net output #0: accuracy = 0.78125
I0429 20:19:12.819720 11879 solver.cpp:229]     Train net output #1: loss = 0.66633 (* 1 = 0.66633 loss)
I0429 20:19:12.819730 11879 solver.cpp:486] Iteration 1260, lr = 0.005
I0429 20:19:33.846953 11879 solver.cpp:214] Iteration 1280, loss = 1.05892
I0429 20:19:33.847122 11879 solver.cpp:229]     Train net output #0: accuracy = 0.65625
I0429 20:19:33.847156 11879 solver.cpp:229]     Train net output #1: loss = 1.05892 (* 1 = 1.05892 loss)
I0429 20:19:33.847177 11879 solver.cpp:486] Iteration 1280, lr = 0.005
I0429 20:19:55.206074 11879 solver.cpp:214] Iteration 1300, loss = 0.709533
I0429 20:19:55.206109 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:19:55.206121 11879 solver.cpp:229]     Train net output #1: loss = 0.709533 (* 1 = 0.709533 loss)
I0429 20:19:55.206130 11879 solver.cpp:486] Iteration 1300, lr = 0.005
I0429 20:20:17.133875 11879 solver.cpp:214] Iteration 1320, loss = 0.451409
I0429 20:20:17.133949 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:20:17.133965 11879 solver.cpp:229]     Train net output #1: loss = 0.451409 (* 1 = 0.451409 loss)
I0429 20:20:17.133973 11879 solver.cpp:486] Iteration 1320, lr = 0.005
I0429 20:20:39.585618 11879 solver.cpp:214] Iteration 1340, loss = 0.74218
I0429 20:20:39.585656 11879 solver.cpp:229]     Train net output #0: accuracy = 0.78125
I0429 20:20:39.585669 11879 solver.cpp:229]     Train net output #1: loss = 0.742179 (* 1 = 0.742179 loss)
I0429 20:20:39.585680 11879 solver.cpp:486] Iteration 1340, lr = 0.005
I0429 20:21:01.533026 11879 solver.cpp:214] Iteration 1360, loss = 0.590585
I0429 20:21:01.533179 11879 solver.cpp:229]     Train net output #0: accuracy = 0.78125
I0429 20:21:01.533203 11879 solver.cpp:229]     Train net output #1: loss = 0.590585 (* 1 = 0.590585 loss)
I0429 20:21:01.533216 11879 solver.cpp:486] Iteration 1360, lr = 0.005
I0429 20:21:22.955523 11879 solver.cpp:214] Iteration 1380, loss = 0.816608
I0429 20:21:22.955556 11879 solver.cpp:229]     Train net output #0: accuracy = 0.71875
I0429 20:21:22.955569 11879 solver.cpp:229]     Train net output #1: loss = 0.816608 (* 1 = 0.816608 loss)
I0429 20:21:22.955579 11879 solver.cpp:486] Iteration 1380, lr = 0.005
I0429 20:21:42.504758 11879 solver.cpp:294] Iteration 1400, Testing net (#0)
I0429 20:25:01.251040 11879 solver.cpp:343]     Test net output #0: accuracy = 0.515938
I0429 20:25:01.251178 11879 solver.cpp:343]     Test net output #1: loss = 1.55813 (* 1 = 1.55813 loss)
I0429 20:25:01.564321 11879 solver.cpp:214] Iteration 1400, loss = 0.395507
I0429 20:25:01.564391 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:25:01.564406 11879 solver.cpp:229]     Train net output #1: loss = 0.395507 (* 1 = 0.395507 loss)
I0429 20:25:01.564419 11879 solver.cpp:486] Iteration 1400, lr = 0.005
I0429 20:25:26.056402 11879 solver.cpp:214] Iteration 1420, loss = 0.809336
I0429 20:25:26.056440 11879 solver.cpp:229]     Train net output #0: accuracy = 0.65625
I0429 20:25:26.056453 11879 solver.cpp:229]     Train net output #1: loss = 0.809336 (* 1 = 0.809336 loss)
I0429 20:25:26.056463 11879 solver.cpp:486] Iteration 1420, lr = 0.005
I0429 20:25:46.668607 11879 solver.cpp:214] Iteration 1440, loss = 0.778828
I0429 20:25:46.668800 11879 solver.cpp:229]     Train net output #0: accuracy = 0.71875
I0429 20:25:46.668824 11879 solver.cpp:229]     Train net output #1: loss = 0.778827 (* 1 = 0.778827 loss)
I0429 20:25:46.668838 11879 solver.cpp:486] Iteration 1440, lr = 0.005
I0429 20:26:08.433328 11879 solver.cpp:214] Iteration 1460, loss = 0.679856
I0429 20:26:08.433363 11879 solver.cpp:229]     Train net output #0: accuracy = 0.75
I0429 20:26:08.433377 11879 solver.cpp:229]     Train net output #1: loss = 0.679856 (* 1 = 0.679856 loss)
I0429 20:26:08.433385 11879 solver.cpp:486] Iteration 1460, lr = 0.005
I0429 20:26:30.158924 11879 solver.cpp:214] Iteration 1480, loss = 0.455129
I0429 20:26:30.159091 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:26:30.159116 11879 solver.cpp:229]     Train net output #1: loss = 0.455129 (* 1 = 0.455129 loss)
I0429 20:26:30.159129 11879 solver.cpp:486] Iteration 1480, lr = 0.005
I0429 20:26:51.434779 11879 solver.cpp:214] Iteration 1500, loss = 0.493934
I0429 20:26:51.434854 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:26:51.434870 11879 solver.cpp:229]     Train net output #1: loss = 0.493934 (* 1 = 0.493934 loss)
I0429 20:26:51.434877 11879 solver.cpp:486] Iteration 1500, lr = 0.005
I0429 20:27:13.988201 11879 solver.cpp:214] Iteration 1520, loss = 0.514625
I0429 20:27:13.988319 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:27:13.988343 11879 solver.cpp:229]     Train net output #1: loss = 0.514625 (* 1 = 0.514625 loss)
I0429 20:27:13.988364 11879 solver.cpp:486] Iteration 1520, lr = 0.005
I0429 20:27:36.445657 11879 solver.cpp:214] Iteration 1540, loss = 0.375463
I0429 20:27:36.445722 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:27:36.445737 11879 solver.cpp:229]     Train net output #1: loss = 0.375463 (* 1 = 0.375463 loss)
I0429 20:27:36.445749 11879 solver.cpp:486] Iteration 1540, lr = 0.005
I0429 20:27:58.731240 11879 solver.cpp:214] Iteration 1560, loss = 0.457983
I0429 20:27:58.731331 11879 solver.cpp:229]     Train net output #0: accuracy = 0.75
I0429 20:27:58.731348 11879 solver.cpp:229]     Train net output #1: loss = 0.457983 (* 1 = 0.457983 loss)
I0429 20:27:58.731358 11879 solver.cpp:486] Iteration 1560, lr = 0.005
I0429 20:28:19.869041 11879 solver.cpp:214] Iteration 1580, loss = 0.427848
I0429 20:28:19.869078 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:28:19.869091 11879 solver.cpp:229]     Train net output #1: loss = 0.427847 (* 1 = 0.427847 loss)
I0429 20:28:19.869101 11879 solver.cpp:486] Iteration 1580, lr = 0.005
I0429 20:28:40.115036 11879 solver.cpp:294] Iteration 1600, Testing net (#0)
I0429 20:31:44.650878 11879 solver.cpp:343]     Test net output #0: accuracy = 0.575938
I0429 20:31:44.651175 11879 solver.cpp:343]     Test net output #1: loss = 1.34705 (* 1 = 1.34705 loss)
I0429 20:31:44.944967 11879 solver.cpp:214] Iteration 1600, loss = 0.414205
I0429 20:31:44.944998 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:31:44.945011 11879 solver.cpp:229]     Train net output #1: loss = 0.414205 (* 1 = 0.414205 loss)
I0429 20:31:44.945019 11879 solver.cpp:486] Iteration 1600, lr = 0.005
I0429 20:32:09.356446 11879 solver.cpp:214] Iteration 1620, loss = 0.598555
I0429 20:32:09.356516 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:32:09.356534 11879 solver.cpp:229]     Train net output #1: loss = 0.598555 (* 1 = 0.598555 loss)
I0429 20:32:09.356546 11879 solver.cpp:486] Iteration 1620, lr = 0.005
I0429 20:32:30.938534 11879 solver.cpp:214] Iteration 1640, loss = 0.519049
I0429 20:32:30.938732 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:32:30.938756 11879 solver.cpp:229]     Train net output #1: loss = 0.519048 (* 1 = 0.519048 loss)
I0429 20:32:30.938771 11879 solver.cpp:486] Iteration 1640, lr = 0.005
I0429 20:32:51.904315 11879 solver.cpp:214] Iteration 1660, loss = 0.429828
I0429 20:32:51.904356 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:32:51.904368 11879 solver.cpp:229]     Train net output #1: loss = 0.429828 (* 1 = 0.429828 loss)
I0429 20:32:51.904377 11879 solver.cpp:486] Iteration 1660, lr = 0.005
I0429 20:33:13.567802 11879 solver.cpp:214] Iteration 1680, loss = 0.709779
I0429 20:33:13.568006 11879 solver.cpp:229]     Train net output #0: accuracy = 0.75
I0429 20:33:13.568028 11879 solver.cpp:229]     Train net output #1: loss = 0.709779 (* 1 = 0.709779 loss)
I0429 20:33:13.568043 11879 solver.cpp:486] Iteration 1680, lr = 0.005
I0429 20:33:35.627599 11879 solver.cpp:214] Iteration 1700, loss = 0.564785
I0429 20:33:35.627640 11879 solver.cpp:229]     Train net output #0: accuracy = 0.71875
I0429 20:33:35.627652 11879 solver.cpp:229]     Train net output #1: loss = 0.564784 (* 1 = 0.564784 loss)
I0429 20:33:35.627661 11879 solver.cpp:486] Iteration 1700, lr = 0.005
I0429 20:33:58.417179 11879 solver.cpp:214] Iteration 1720, loss = 0.363969
I0429 20:33:58.417358 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:33:58.417376 11879 solver.cpp:229]     Train net output #1: loss = 0.363969 (* 1 = 0.363969 loss)
I0429 20:33:58.417385 11879 solver.cpp:486] Iteration 1720, lr = 0.005
I0429 20:34:20.779253 11879 solver.cpp:214] Iteration 1740, loss = 0.639138
I0429 20:34:20.779291 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:34:20.779304 11879 solver.cpp:229]     Train net output #1: loss = 0.639138 (* 1 = 0.639138 loss)
I0429 20:34:20.779314 11879 solver.cpp:486] Iteration 1740, lr = 0.005
I0429 20:34:42.608925 11879 solver.cpp:214] Iteration 1760, loss = 0.470155
I0429 20:34:42.609194 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:34:42.609218 11879 solver.cpp:229]     Train net output #1: loss = 0.470155 (* 1 = 0.470155 loss)
I0429 20:34:42.609233 11879 solver.cpp:486] Iteration 1760, lr = 0.005
I0429 20:35:03.304241 11879 solver.cpp:214] Iteration 1780, loss = 0.455821
I0429 20:35:03.304281 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 20:35:03.304294 11879 solver.cpp:229]     Train net output #1: loss = 0.455821 (* 1 = 0.455821 loss)
I0429 20:35:03.304304 11879 solver.cpp:486] Iteration 1780, lr = 0.005
I0429 20:35:23.474141 11879 solver.cpp:294] Iteration 1800, Testing net (#0)
I0429 20:38:12.678241 11879 solver.cpp:343]     Test net output #0: accuracy = 0.525
I0429 20:38:12.678310 11879 solver.cpp:343]     Test net output #1: loss = 1.54893 (* 1 = 1.54893 loss)
I0429 20:38:13.040382 11879 solver.cpp:214] Iteration 1800, loss = 0.299004
I0429 20:38:13.040448 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:38:13.040464 11879 solver.cpp:229]     Train net output #1: loss = 0.299004 (* 1 = 0.299004 loss)
I0429 20:38:13.040477 11879 solver.cpp:486] Iteration 1800, lr = 0.005
I0429 20:39:07.185680 11879 solver.cpp:214] Iteration 1820, loss = 0.553761
I0429 20:39:07.185847 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:39:07.185869 11879 solver.cpp:229]     Train net output #1: loss = 0.55376 (* 1 = 0.55376 loss)
I0429 20:39:07.185883 11879 solver.cpp:486] Iteration 1820, lr = 0.005
I0429 20:39:46.337899 11879 solver.cpp:214] Iteration 1840, loss = 0.543424
I0429 20:39:46.338048 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:39:46.338071 11879 solver.cpp:229]     Train net output #1: loss = 0.543424 (* 1 = 0.543424 loss)
I0429 20:39:46.338084 11879 solver.cpp:486] Iteration 1840, lr = 0.005
I0429 20:40:07.282642 11879 solver.cpp:214] Iteration 1860, loss = 0.80428
I0429 20:40:07.282688 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:40:07.282707 11879 solver.cpp:229]     Train net output #1: loss = 0.80428 (* 1 = 0.80428 loss)
I0429 20:40:07.282721 11879 solver.cpp:486] Iteration 1860, lr = 0.005
I0429 20:40:27.540205 11879 solver.cpp:214] Iteration 1880, loss = 0.382027
I0429 20:40:27.540360 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:40:27.540388 11879 solver.cpp:229]     Train net output #1: loss = 0.382027 (* 1 = 0.382027 loss)
I0429 20:40:27.540410 11879 solver.cpp:486] Iteration 1880, lr = 0.005
I0429 20:40:48.599059 11879 solver.cpp:214] Iteration 1900, loss = 0.607453
I0429 20:40:48.599093 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:40:48.599107 11879 solver.cpp:229]     Train net output #1: loss = 0.607453 (* 1 = 0.607453 loss)
I0429 20:40:48.599114 11879 solver.cpp:486] Iteration 1900, lr = 0.005
I0429 20:41:09.166682 11879 solver.cpp:214] Iteration 1920, loss = 0.332184
I0429 20:41:09.166895 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:41:09.166920 11879 solver.cpp:229]     Train net output #1: loss = 0.332184 (* 1 = 0.332184 loss)
I0429 20:41:09.166934 11879 solver.cpp:486] Iteration 1920, lr = 0.005
I0429 20:41:29.663455 11879 solver.cpp:214] Iteration 1940, loss = 0.432246
I0429 20:41:29.663493 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:41:29.663506 11879 solver.cpp:229]     Train net output #1: loss = 0.432246 (* 1 = 0.432246 loss)
I0429 20:41:29.663516 11879 solver.cpp:486] Iteration 1940, lr = 0.005
I0429 20:41:51.152045 11879 solver.cpp:214] Iteration 1960, loss = 0.426402
I0429 20:41:51.152138 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:41:51.152155 11879 solver.cpp:229]     Train net output #1: loss = 0.426401 (* 1 = 0.426401 loss)
I0429 20:41:51.152164 11879 solver.cpp:486] Iteration 1960, lr = 0.005
I0429 20:42:12.616842 11879 solver.cpp:214] Iteration 1980, loss = 0.717144
I0429 20:42:12.616899 11879 solver.cpp:229]     Train net output #0: accuracy = 0.75
I0429 20:42:12.616919 11879 solver.cpp:229]     Train net output #1: loss = 0.717143 (* 1 = 0.717143 loss)
I0429 20:42:12.616932 11879 solver.cpp:486] Iteration 1980, lr = 0.005
I0429 20:42:32.319787 11879 solver.cpp:294] Iteration 2000, Testing net (#0)
I0429 20:44:46.605048 11879 solver.cpp:343]     Test net output #0: accuracy = 0.58125
I0429 20:44:46.605140 11879 solver.cpp:343]     Test net output #1: loss = 1.56068 (* 1 = 1.56068 loss)
I0429 20:44:46.980428 11879 solver.cpp:214] Iteration 2000, loss = 0.475748
I0429 20:44:46.980470 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:44:46.980484 11879 solver.cpp:229]     Train net output #1: loss = 0.475747 (* 1 = 0.475747 loss)
I0429 20:44:46.980494 11879 solver.cpp:486] Iteration 2000, lr = 0.005
I0429 20:45:12.408996 11879 solver.cpp:214] Iteration 2020, loss = 0.613735
I0429 20:45:12.409031 11879 solver.cpp:229]     Train net output #0: accuracy = 0.78125
I0429 20:45:12.409044 11879 solver.cpp:229]     Train net output #1: loss = 0.613735 (* 1 = 0.613735 loss)
I0429 20:45:12.409052 11879 solver.cpp:486] Iteration 2020, lr = 0.005
I0429 20:45:34.722270 11879 solver.cpp:214] Iteration 2040, loss = 0.507523
I0429 20:45:34.722407 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:45:34.722435 11879 solver.cpp:229]     Train net output #1: loss = 0.507523 (* 1 = 0.507523 loss)
I0429 20:45:34.722456 11879 solver.cpp:486] Iteration 2040, lr = 0.005
I0429 20:45:55.796090 11879 solver.cpp:214] Iteration 2060, loss = 0.502346
I0429 20:45:55.796135 11879 solver.cpp:229]     Train net output #0: accuracy = 0.78125
I0429 20:45:55.796157 11879 solver.cpp:229]     Train net output #1: loss = 0.502346 (* 1 = 0.502346 loss)
I0429 20:45:55.796172 11879 solver.cpp:486] Iteration 2060, lr = 0.005
I0429 20:46:16.534047 11879 solver.cpp:214] Iteration 2080, loss = 0.346638
I0429 20:46:16.534273 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:46:16.534297 11879 solver.cpp:229]     Train net output #1: loss = 0.346638 (* 1 = 0.346638 loss)
I0429 20:46:16.534312 11879 solver.cpp:486] Iteration 2080, lr = 0.005
I0429 20:46:37.204605 11879 solver.cpp:214] Iteration 2100, loss = 0.334551
I0429 20:46:37.204653 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 20:46:37.204666 11879 solver.cpp:229]     Train net output #1: loss = 0.334551 (* 1 = 0.334551 loss)
I0429 20:46:37.204676 11879 solver.cpp:486] Iteration 2100, lr = 0.005
I0429 20:46:57.754282 11879 solver.cpp:214] Iteration 2120, loss = 0.272679
I0429 20:46:57.754503 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 20:46:57.754528 11879 solver.cpp:229]     Train net output #1: loss = 0.272679 (* 1 = 0.272679 loss)
I0429 20:46:57.754541 11879 solver.cpp:486] Iteration 2120, lr = 0.005
I0429 20:47:18.304517 11879 solver.cpp:214] Iteration 2140, loss = 0.193487
I0429 20:47:18.304558 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:47:18.304571 11879 solver.cpp:229]     Train net output #1: loss = 0.193487 (* 1 = 0.193487 loss)
I0429 20:47:18.304580 11879 solver.cpp:486] Iteration 2140, lr = 0.005
I0429 20:47:39.307711 11879 solver.cpp:214] Iteration 2160, loss = 0.271348
I0429 20:47:39.307973 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:47:39.307997 11879 solver.cpp:229]     Train net output #1: loss = 0.271348 (* 1 = 0.271348 loss)
I0429 20:47:39.308010 11879 solver.cpp:486] Iteration 2160, lr = 0.005
I0429 20:48:00.259431 11879 solver.cpp:214] Iteration 2180, loss = 0.395151
I0429 20:48:00.259472 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:48:00.259485 11879 solver.cpp:229]     Train net output #1: loss = 0.395151 (* 1 = 0.395151 loss)
I0429 20:48:00.259493 11879 solver.cpp:486] Iteration 2180, lr = 0.005
I0429 20:48:20.005008 11879 solver.cpp:294] Iteration 2200, Testing net (#0)
I0429 20:51:20.221696 11879 solver.cpp:343]     Test net output #0: accuracy = 0.528906
I0429 20:51:20.221848 11879 solver.cpp:343]     Test net output #1: loss = 1.79531 (* 1 = 1.79531 loss)
I0429 20:51:20.586275 11879 solver.cpp:214] Iteration 2200, loss = 0.33908
I0429 20:51:20.586313 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:51:20.586325 11879 solver.cpp:229]     Train net output #1: loss = 0.339079 (* 1 = 0.339079 loss)
I0429 20:51:20.586333 11879 solver.cpp:486] Iteration 2200, lr = 0.005
I0429 20:51:44.244830 11879 solver.cpp:214] Iteration 2220, loss = 0.288689
I0429 20:51:44.244873 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 20:51:44.244892 11879 solver.cpp:229]     Train net output #1: loss = 0.288689 (* 1 = 0.288689 loss)
I0429 20:51:44.244905 11879 solver.cpp:486] Iteration 2220, lr = 0.005
I0429 20:52:05.901952 11879 solver.cpp:214] Iteration 2240, loss = 0.590109
I0429 20:52:05.902153 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 20:52:05.902176 11879 solver.cpp:229]     Train net output #1: loss = 0.590109 (* 1 = 0.590109 loss)
I0429 20:52:05.902189 11879 solver.cpp:486] Iteration 2240, lr = 0.005
I0429 20:52:28.304213 11879 solver.cpp:214] Iteration 2260, loss = 0.439774
I0429 20:52:28.304273 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:52:28.304293 11879 solver.cpp:229]     Train net output #1: loss = 0.439774 (* 1 = 0.439774 loss)
I0429 20:52:28.304308 11879 solver.cpp:486] Iteration 2260, lr = 0.005
I0429 20:52:49.403625 11879 solver.cpp:214] Iteration 2280, loss = 0.310518
I0429 20:52:49.403753 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:52:49.403779 11879 solver.cpp:229]     Train net output #1: loss = 0.310518 (* 1 = 0.310518 loss)
I0429 20:52:49.403795 11879 solver.cpp:486] Iteration 2280, lr = 0.005
I0429 20:53:10.237560 11879 solver.cpp:214] Iteration 2300, loss = 0.483057
I0429 20:53:10.237601 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 20:53:10.237613 11879 solver.cpp:229]     Train net output #1: loss = 0.483057 (* 1 = 0.483057 loss)
I0429 20:53:10.237622 11879 solver.cpp:486] Iteration 2300, lr = 0.005
I0429 20:53:31.992086 11879 solver.cpp:214] Iteration 2320, loss = 0.519957
I0429 20:53:31.992367 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:53:31.992395 11879 solver.cpp:229]     Train net output #1: loss = 0.519957 (* 1 = 0.519957 loss)
I0429 20:53:31.992410 11879 solver.cpp:486] Iteration 2320, lr = 0.005
I0429 20:53:53.722548 11879 solver.cpp:214] Iteration 2340, loss = 0.406656
I0429 20:53:53.722590 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:53:53.722604 11879 solver.cpp:229]     Train net output #1: loss = 0.406655 (* 1 = 0.406655 loss)
I0429 20:53:53.722614 11879 solver.cpp:486] Iteration 2340, lr = 0.005
I0429 20:54:44.529825 11879 solver.cpp:214] Iteration 2360, loss = 1.19205
I0429 20:54:44.530050 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 20:54:44.530083 11879 solver.cpp:229]     Train net output #1: loss = 1.19205 (* 1 = 1.19205 loss)
I0429 20:54:44.530107 11879 solver.cpp:486] Iteration 2360, lr = 0.005
I0429 20:55:27.321274 11879 solver.cpp:214] Iteration 2380, loss = 0.148716
I0429 20:55:27.321595 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 20:55:27.321635 11879 solver.cpp:229]     Train net output #1: loss = 0.148716 (* 1 = 0.148716 loss)
I0429 20:55:27.321660 11879 solver.cpp:486] Iteration 2380, lr = 0.005
I0429 20:55:48.823683 11879 solver.cpp:294] Iteration 2400, Testing net (#0)
I0429 20:58:54.644613 11879 solver.cpp:343]     Test net output #0: accuracy = 0.585312
I0429 20:58:54.655113 11879 solver.cpp:343]     Test net output #1: loss = 1.70953 (* 1 = 1.70953 loss)
I0429 20:58:54.965251 11879 solver.cpp:214] Iteration 2400, loss = 0.490848
I0429 20:58:54.965296 11879 solver.cpp:229]     Train net output #0: accuracy = 0.75
I0429 20:58:54.965314 11879 solver.cpp:229]     Train net output #1: loss = 0.490847 (* 1 = 0.490847 loss)
I0429 20:58:54.965328 11879 solver.cpp:486] Iteration 2400, lr = 0.005
I0429 20:59:19.721431 11879 solver.cpp:214] Iteration 2420, loss = 0.366752
I0429 20:59:19.721468 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 20:59:19.721482 11879 solver.cpp:229]     Train net output #1: loss = 0.366752 (* 1 = 0.366752 loss)
I0429 20:59:19.721492 11879 solver.cpp:486] Iteration 2420, lr = 0.005
I0429 20:59:41.270356 11879 solver.cpp:214] Iteration 2440, loss = 0.403195
I0429 20:59:41.270437 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 20:59:41.270452 11879 solver.cpp:229]     Train net output #1: loss = 0.403195 (* 1 = 0.403195 loss)
I0429 20:59:41.270462 11879 solver.cpp:486] Iteration 2440, lr = 0.005
I0429 21:00:02.648618 11879 solver.cpp:214] Iteration 2460, loss = 0.250398
I0429 21:00:02.648689 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:00:02.648717 11879 solver.cpp:229]     Train net output #1: loss = 0.250398 (* 1 = 0.250398 loss)
I0429 21:00:02.648746 11879 solver.cpp:486] Iteration 2460, lr = 0.005
I0429 21:00:24.399552 11879 solver.cpp:214] Iteration 2480, loss = 0.242041
I0429 21:00:24.399642 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:00:24.399657 11879 solver.cpp:229]     Train net output #1: loss = 0.242041 (* 1 = 0.242041 loss)
I0429 21:00:24.399668 11879 solver.cpp:486] Iteration 2480, lr = 0.005
I0429 21:00:46.125249 11879 solver.cpp:214] Iteration 2500, loss = 0.134337
I0429 21:00:46.125285 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:00:46.125298 11879 solver.cpp:229]     Train net output #1: loss = 0.134337 (* 1 = 0.134337 loss)
I0429 21:00:46.125308 11879 solver.cpp:486] Iteration 2500, lr = 0.005
I0429 21:01:08.489413 11879 solver.cpp:214] Iteration 2520, loss = 0.359123
I0429 21:01:08.489558 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 21:01:08.489581 11879 solver.cpp:229]     Train net output #1: loss = 0.359123 (* 1 = 0.359123 loss)
I0429 21:01:08.489595 11879 solver.cpp:486] Iteration 2520, lr = 0.005
I0429 21:01:30.810660 11879 solver.cpp:214] Iteration 2540, loss = 0.47036
I0429 21:01:30.810706 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 21:01:30.810727 11879 solver.cpp:229]     Train net output #1: loss = 0.47036 (* 1 = 0.47036 loss)
I0429 21:01:30.810741 11879 solver.cpp:486] Iteration 2540, lr = 0.005
I0429 21:01:52.865617 11879 solver.cpp:214] Iteration 2560, loss = 0.222495
I0429 21:01:52.865820 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:01:52.865845 11879 solver.cpp:229]     Train net output #1: loss = 0.222495 (* 1 = 0.222495 loss)
I0429 21:01:52.865859 11879 solver.cpp:486] Iteration 2560, lr = 0.005
I0429 21:02:14.471961 11879 solver.cpp:214] Iteration 2580, loss = 0.308678
I0429 21:02:14.472002 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:02:14.472015 11879 solver.cpp:229]     Train net output #1: loss = 0.308678 (* 1 = 0.308678 loss)
I0429 21:02:14.472024 11879 solver.cpp:486] Iteration 2580, lr = 0.005
I0429 21:02:34.188361 11879 solver.cpp:294] Iteration 2600, Testing net (#0)
I0429 21:04:39.059666 11879 solver.cpp:343]     Test net output #0: accuracy = 0.595625
I0429 21:04:39.081014 11879 solver.cpp:343]     Test net output #1: loss = 1.75254 (* 1 = 1.75254 loss)
I0429 21:04:39.376675 11879 solver.cpp:214] Iteration 2600, loss = 0.119934
I0429 21:04:39.376715 11879 solver.cpp:229]     Train net output #0: accuracy = 1
I0429 21:04:39.376729 11879 solver.cpp:229]     Train net output #1: loss = 0.119934 (* 1 = 0.119934 loss)
I0429 21:04:39.376737 11879 solver.cpp:486] Iteration 2600, lr = 0.005
I0429 21:05:02.695334 11879 solver.cpp:214] Iteration 2620, loss = 0.348218
I0429 21:05:02.695377 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:05:02.695391 11879 solver.cpp:229]     Train net output #1: loss = 0.348218 (* 1 = 0.348218 loss)
I0429 21:05:02.695400 11879 solver.cpp:486] Iteration 2620, lr = 0.005
I0429 21:05:23.989266 11879 solver.cpp:214] Iteration 2640, loss = 0.604637
I0429 21:05:23.989408 11879 solver.cpp:229]     Train net output #0: accuracy = 0.78125
I0429 21:05:23.989429 11879 solver.cpp:229]     Train net output #1: loss = 0.604637 (* 1 = 0.604637 loss)
I0429 21:05:23.989444 11879 solver.cpp:486] Iteration 2640, lr = 0.005
I0429 21:05:44.879691 11879 solver.cpp:214] Iteration 2660, loss = 0.285377
I0429 21:05:44.879737 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:05:44.879751 11879 solver.cpp:229]     Train net output #1: loss = 0.285377 (* 1 = 0.285377 loss)
I0429 21:05:44.879760 11879 solver.cpp:486] Iteration 2660, lr = 0.005
I0429 21:06:05.311167 11879 solver.cpp:214] Iteration 2680, loss = 0.214765
I0429 21:06:05.311377 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:06:05.311400 11879 solver.cpp:229]     Train net output #1: loss = 0.214765 (* 1 = 0.214765 loss)
I0429 21:06:05.311420 11879 solver.cpp:486] Iteration 2680, lr = 0.005
I0429 21:06:26.236843 11879 solver.cpp:214] Iteration 2700, loss = 0.381497
I0429 21:06:26.236887 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 21:06:26.236908 11879 solver.cpp:229]     Train net output #1: loss = 0.381497 (* 1 = 0.381497 loss)
I0429 21:06:26.236924 11879 solver.cpp:486] Iteration 2700, lr = 0.005
I0429 21:06:48.230870 11879 solver.cpp:214] Iteration 2720, loss = 0.368193
I0429 21:06:48.231017 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 21:06:48.231050 11879 solver.cpp:229]     Train net output #1: loss = 0.368193 (* 1 = 0.368193 loss)
I0429 21:06:48.231072 11879 solver.cpp:486] Iteration 2720, lr = 0.005
I0429 21:07:09.356178 11879 solver.cpp:214] Iteration 2740, loss = 0.28688
I0429 21:07:09.356218 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:07:09.356231 11879 solver.cpp:229]     Train net output #1: loss = 0.286879 (* 1 = 0.286879 loss)
I0429 21:07:09.356240 11879 solver.cpp:486] Iteration 2740, lr = 0.005
I0429 21:07:31.574733 11879 solver.cpp:214] Iteration 2760, loss = 0.344134
I0429 21:07:31.574879 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:07:31.574904 11879 solver.cpp:229]     Train net output #1: loss = 0.344134 (* 1 = 0.344134 loss)
I0429 21:07:31.574918 11879 solver.cpp:486] Iteration 2760, lr = 0.005
I0429 21:07:52.301690 11879 solver.cpp:214] Iteration 2780, loss = 0.368563
I0429 21:07:52.301733 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 21:07:52.301754 11879 solver.cpp:229]     Train net output #1: loss = 0.368563 (* 1 = 0.368563 loss)
I0429 21:07:52.301769 11879 solver.cpp:486] Iteration 2780, lr = 0.005
I0429 21:08:11.930565 11879 solver.cpp:294] Iteration 2800, Testing net (#0)
I0429 21:11:57.464366 11879 solver.cpp:343]     Test net output #0: accuracy = 0.573125
I0429 21:11:57.464527 11879 solver.cpp:343]     Test net output #1: loss = 1.7576 (* 1 = 1.7576 loss)
I0429 21:11:57.630089 11879 solver.cpp:214] Iteration 2800, loss = 0.321896
I0429 21:11:57.630123 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:11:57.630136 11879 solver.cpp:229]     Train net output #1: loss = 0.321896 (* 1 = 0.321896 loss)
I0429 21:11:57.630146 11879 solver.cpp:486] Iteration 2800, lr = 0.005
I0429 21:12:30.434942 11879 solver.cpp:214] Iteration 2820, loss = 0.242591
I0429 21:12:30.435159 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 21:12:30.435183 11879 solver.cpp:229]     Train net output #1: loss = 0.242591 (* 1 = 0.242591 loss)
I0429 21:12:30.435196 11879 solver.cpp:486] Iteration 2820, lr = 0.005
I0429 21:12:55.134306 11879 solver.cpp:214] Iteration 2840, loss = 0.233871
I0429 21:12:55.134341 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:12:55.134354 11879 solver.cpp:229]     Train net output #1: loss = 0.233871 (* 1 = 0.233871 loss)
I0429 21:12:55.134363 11879 solver.cpp:486] Iteration 2840, lr = 0.005
I0429 21:13:15.980020 11879 solver.cpp:214] Iteration 2860, loss = 0.383619
I0429 21:13:15.980306 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:13:15.980332 11879 solver.cpp:229]     Train net output #1: loss = 0.383619 (* 1 = 0.383619 loss)
I0429 21:13:15.980350 11879 solver.cpp:486] Iteration 2860, lr = 0.005
I0429 21:13:36.895243 11879 solver.cpp:214] Iteration 2880, loss = 0.515552
I0429 21:13:36.895311 11879 solver.cpp:229]     Train net output #0: accuracy = 0.8125
I0429 21:13:36.895325 11879 solver.cpp:229]     Train net output #1: loss = 0.515552 (* 1 = 0.515552 loss)
I0429 21:13:36.895335 11879 solver.cpp:486] Iteration 2880, lr = 0.005
I0429 21:13:58.992580 11879 solver.cpp:214] Iteration 2900, loss = 0.261894
I0429 21:13:58.992820 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:13:58.992846 11879 solver.cpp:229]     Train net output #1: loss = 0.261894 (* 1 = 0.261894 loss)
I0429 21:13:58.992858 11879 solver.cpp:486] Iteration 2900, lr = 0.005
I0429 21:14:25.896252 11879 solver.cpp:214] Iteration 2920, loss = 0.349608
I0429 21:14:25.896291 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 21:14:25.896303 11879 solver.cpp:229]     Train net output #1: loss = 0.349608 (* 1 = 0.349608 loss)
I0429 21:14:25.896313 11879 solver.cpp:486] Iteration 2920, lr = 0.005
I0429 21:15:16.430083 11879 solver.cpp:214] Iteration 2940, loss = 0.134738
I0429 21:15:16.430290 11879 solver.cpp:229]     Train net output #0: accuracy = 1
I0429 21:15:16.430315 11879 solver.cpp:229]     Train net output #1: loss = 0.134738 (* 1 = 0.134738 loss)
I0429 21:15:16.430328 11879 solver.cpp:486] Iteration 2940, lr = 0.005
I0429 21:16:04.808470 11879 solver.cpp:214] Iteration 2960, loss = 0.258341
I0429 21:16:04.808614 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:16:04.808637 11879 solver.cpp:229]     Train net output #1: loss = 0.258341 (* 1 = 0.258341 loss)
I0429 21:16:04.808651 11879 solver.cpp:486] Iteration 2960, lr = 0.005
I0429 21:16:35.900054 11879 solver.cpp:214] Iteration 2980, loss = 0.165338
I0429 21:16:35.900218 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:16:35.900240 11879 solver.cpp:229]     Train net output #1: loss = 0.165338 (* 1 = 0.165338 loss)
I0429 21:16:35.900254 11879 solver.cpp:486] Iteration 2980, lr = 0.005
I0429 21:16:55.986047 11879 solver.cpp:294] Iteration 3000, Testing net (#0)
I0429 21:20:04.290383 11879 solver.cpp:343]     Test net output #0: accuracy = 0.604062
I0429 21:20:04.290601 11879 solver.cpp:343]     Test net output #1: loss = 1.63596 (* 1 = 1.63596 loss)
I0429 21:20:04.577800 11879 solver.cpp:214] Iteration 3000, loss = 0.43088
I0429 21:20:04.577834 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 21:20:04.577847 11879 solver.cpp:229]     Train net output #1: loss = 0.43088 (* 1 = 0.43088 loss)
I0429 21:20:04.577857 11879 solver.cpp:486] Iteration 3000, lr = 0.005
I0429 21:20:28.702883 11879 solver.cpp:214] Iteration 3020, loss = 0.180061
I0429 21:20:28.702914 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:20:28.702929 11879 solver.cpp:229]     Train net output #1: loss = 0.180061 (* 1 = 0.180061 loss)
I0429 21:20:28.702936 11879 solver.cpp:486] Iteration 3020, lr = 0.005
I0429 21:20:50.437053 11879 solver.cpp:214] Iteration 3040, loss = 0.138963
I0429 21:20:50.437212 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:20:50.437237 11879 solver.cpp:229]     Train net output #1: loss = 0.138963 (* 1 = 0.138963 loss)
I0429 21:20:50.437250 11879 solver.cpp:486] Iteration 3040, lr = 0.005
I0429 21:21:12.103204 11879 solver.cpp:214] Iteration 3060, loss = 0.382317
I0429 21:21:12.103245 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 21:21:12.103257 11879 solver.cpp:229]     Train net output #1: loss = 0.382317 (* 1 = 0.382317 loss)
I0429 21:21:12.103266 11879 solver.cpp:486] Iteration 3060, lr = 0.005
I0429 21:21:34.747561 11879 solver.cpp:214] Iteration 3080, loss = 0.304112
I0429 21:21:34.747766 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:21:34.747791 11879 solver.cpp:229]     Train net output #1: loss = 0.304111 (* 1 = 0.304111 loss)
I0429 21:21:34.747804 11879 solver.cpp:486] Iteration 3080, lr = 0.005
I0429 21:21:56.454855 11879 solver.cpp:214] Iteration 3100, loss = 0.325735
I0429 21:21:56.454931 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:21:56.454957 11879 solver.cpp:229]     Train net output #1: loss = 0.325735 (* 1 = 0.325735 loss)
I0429 21:21:56.454975 11879 solver.cpp:486] Iteration 3100, lr = 0.005
I0429 21:22:17.545169 11879 solver.cpp:214] Iteration 3120, loss = 0.177825
I0429 21:22:17.545270 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:22:17.545295 11879 solver.cpp:229]     Train net output #1: loss = 0.177825 (* 1 = 0.177825 loss)
I0429 21:22:17.545310 11879 solver.cpp:486] Iteration 3120, lr = 0.005
I0429 21:22:38.488394 11879 solver.cpp:214] Iteration 3140, loss = 1.81055
I0429 21:22:38.488523 11879 solver.cpp:229]     Train net output #0: accuracy = 0.5
I0429 21:22:38.488590 11879 solver.cpp:229]     Train net output #1: loss = 1.81055 (* 1 = 1.81055 loss)
I0429 21:22:38.488637 11879 solver.cpp:486] Iteration 3140, lr = 0.005
I0429 21:22:59.691645 11879 solver.cpp:214] Iteration 3160, loss = 0.365406
I0429 21:22:59.691893 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:22:59.691917 11879 solver.cpp:229]     Train net output #1: loss = 0.365406 (* 1 = 0.365406 loss)
I0429 21:22:59.691931 11879 solver.cpp:486] Iteration 3160, lr = 0.005
I0429 21:23:20.724174 11879 solver.cpp:214] Iteration 3180, loss = 0.344663
I0429 21:23:20.724210 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 21:23:20.724225 11879 solver.cpp:229]     Train net output #1: loss = 0.344663 (* 1 = 0.344663 loss)
I0429 21:23:20.724233 11879 solver.cpp:486] Iteration 3180, lr = 0.005
I0429 21:23:40.985741 11879 solver.cpp:294] Iteration 3200, Testing net (#0)
I0429 21:25:59.441215 11879 solver.cpp:343]     Test net output #0: accuracy = 0.592812
I0429 21:25:59.441282 11879 solver.cpp:343]     Test net output #1: loss = 1.85516 (* 1 = 1.85516 loss)
I0429 21:25:59.701083 11879 solver.cpp:214] Iteration 3200, loss = 0.175966
I0429 21:25:59.701123 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:25:59.701136 11879 solver.cpp:229]     Train net output #1: loss = 0.175966 (* 1 = 0.175966 loss)
I0429 21:25:59.701145 11879 solver.cpp:486] Iteration 3200, lr = 0.005
I0429 21:26:21.261054 11879 solver.cpp:214] Iteration 3220, loss = 0.245851
I0429 21:26:21.261126 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:26:21.261143 11879 solver.cpp:229]     Train net output #1: loss = 0.24585 (* 1 = 0.24585 loss)
I0429 21:26:21.261157 11879 solver.cpp:486] Iteration 3220, lr = 0.005
I0429 21:26:42.278669 11879 solver.cpp:214] Iteration 3240, loss = 0.229139
I0429 21:26:42.278803 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:26:42.278836 11879 solver.cpp:229]     Train net output #1: loss = 0.229139 (* 1 = 0.229139 loss)
I0429 21:26:42.278857 11879 solver.cpp:486] Iteration 3240, lr = 0.005
I0429 21:27:03.906673 11879 solver.cpp:214] Iteration 3260, loss = 0.275011
I0429 21:27:03.906714 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:27:03.906735 11879 solver.cpp:229]     Train net output #1: loss = 0.275011 (* 1 = 0.275011 loss)
I0429 21:27:03.906750 11879 solver.cpp:486] Iteration 3260, lr = 0.005
I0429 21:27:24.918081 11879 solver.cpp:214] Iteration 3280, loss = 0.14914
I0429 21:27:24.918192 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:27:24.918210 11879 solver.cpp:229]     Train net output #1: loss = 0.14914 (* 1 = 0.14914 loss)
I0429 21:27:24.918220 11879 solver.cpp:486] Iteration 3280, lr = 0.005
I0429 21:27:46.396903 11879 solver.cpp:214] Iteration 3300, loss = 0.126308
I0429 21:27:46.396965 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:27:46.396978 11879 solver.cpp:229]     Train net output #1: loss = 0.126307 (* 1 = 0.126307 loss)
I0429 21:27:46.396987 11879 solver.cpp:486] Iteration 3300, lr = 0.005
I0429 21:28:08.608435 11879 solver.cpp:214] Iteration 3320, loss = 0.272253
I0429 21:28:08.608541 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 21:28:08.608558 11879 solver.cpp:229]     Train net output #1: loss = 0.272253 (* 1 = 0.272253 loss)
I0429 21:28:08.608567 11879 solver.cpp:486] Iteration 3320, lr = 0.005
I0429 21:28:29.714889 11879 solver.cpp:214] Iteration 3340, loss = 0.267039
I0429 21:28:29.714934 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:28:29.714956 11879 solver.cpp:229]     Train net output #1: loss = 0.267039 (* 1 = 0.267039 loss)
I0429 21:28:29.714970 11879 solver.cpp:486] Iteration 3340, lr = 0.005
I0429 21:28:51.049159 11879 solver.cpp:214] Iteration 3360, loss = 0.213696
I0429 21:28:51.049329 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:28:51.049365 11879 solver.cpp:229]     Train net output #1: loss = 0.213696 (* 1 = 0.213696 loss)
I0429 21:28:51.049389 11879 solver.cpp:486] Iteration 3360, lr = 0.005
I0429 21:29:17.173197 11879 solver.cpp:214] Iteration 3380, loss = 0.206282
I0429 21:29:17.173276 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:29:17.173292 11879 solver.cpp:229]     Train net output #1: loss = 0.206282 (* 1 = 0.206282 loss)
I0429 21:29:17.173305 11879 solver.cpp:486] Iteration 3380, lr = 0.005
I0429 21:29:37.596205 11879 solver.cpp:294] Iteration 3400, Testing net (#0)
I0429 21:32:25.606649 11879 solver.cpp:343]     Test net output #0: accuracy = 0.553906
I0429 21:32:25.606837 11879 solver.cpp:343]     Test net output #1: loss = 1.99572 (* 1 = 1.99572 loss)
I0429 21:32:25.875895 11879 solver.cpp:214] Iteration 3400, loss = 0.172246
I0429 21:32:25.875932 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:32:25.875946 11879 solver.cpp:229]     Train net output #1: loss = 0.172245 (* 1 = 0.172245 loss)
I0429 21:32:25.875954 11879 solver.cpp:486] Iteration 3400, lr = 0.005
I0429 21:32:50.216075 11879 solver.cpp:214] Iteration 3420, loss = 0.0555015
I0429 21:32:50.216121 11879 solver.cpp:229]     Train net output #0: accuracy = 1
I0429 21:32:50.216135 11879 solver.cpp:229]     Train net output #1: loss = 0.0555014 (* 1 = 0.0555014 loss)
I0429 21:32:50.216145 11879 solver.cpp:486] Iteration 3420, lr = 0.005
I0429 21:33:11.581218 11879 solver.cpp:214] Iteration 3440, loss = 0.333164
I0429 21:33:11.581439 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:33:11.581480 11879 solver.cpp:229]     Train net output #1: loss = 0.333164 (* 1 = 0.333164 loss)
I0429 21:33:11.581502 11879 solver.cpp:486] Iteration 3440, lr = 0.005
I0429 21:33:32.484431 11879 solver.cpp:214] Iteration 3460, loss = 0.0732869
I0429 21:33:32.484464 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:33:32.484478 11879 solver.cpp:229]     Train net output #1: loss = 0.0732867 (* 1 = 0.0732867 loss)
I0429 21:33:32.484488 11879 solver.cpp:486] Iteration 3460, lr = 0.005
I0429 21:33:53.647616 11879 solver.cpp:214] Iteration 3480, loss = 0.288815
I0429 21:33:53.647867 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:33:53.647891 11879 solver.cpp:229]     Train net output #1: loss = 0.288815 (* 1 = 0.288815 loss)
I0429 21:33:53.647905 11879 solver.cpp:486] Iteration 3480, lr = 0.005
I0429 21:34:26.503250 11879 solver.cpp:214] Iteration 3500, loss = 0.474056
I0429 21:34:26.503389 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 21:34:26.503413 11879 solver.cpp:229]     Train net output #1: loss = 0.474055 (* 1 = 0.474055 loss)
I0429 21:34:26.503432 11879 solver.cpp:486] Iteration 3500, lr = 0.005
I0429 21:34:50.012043 11879 solver.cpp:214] Iteration 3520, loss = 0.339155
I0429 21:34:50.012084 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 21:34:50.012102 11879 solver.cpp:229]     Train net output #1: loss = 0.339155 (* 1 = 0.339155 loss)
I0429 21:34:50.012112 11879 solver.cpp:486] Iteration 3520, lr = 0.005
I0429 21:35:11.346664 11879 solver.cpp:214] Iteration 3540, loss = 0.148632
I0429 21:35:11.346770 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:35:11.346786 11879 solver.cpp:229]     Train net output #1: loss = 0.148632 (* 1 = 0.148632 loss)
I0429 21:35:11.346796 11879 solver.cpp:486] Iteration 3540, lr = 0.005
I0429 21:35:32.463865 11879 solver.cpp:214] Iteration 3560, loss = 0.193692
I0429 21:35:32.463902 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:35:32.463915 11879 solver.cpp:229]     Train net output #1: loss = 0.193692 (* 1 = 0.193692 loss)
I0429 21:35:32.463923 11879 solver.cpp:486] Iteration 3560, lr = 0.005
I0429 21:35:53.234730 11879 solver.cpp:214] Iteration 3580, loss = 0.180115
I0429 21:35:53.234879 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:35:53.234904 11879 solver.cpp:229]     Train net output #1: loss = 0.180115 (* 1 = 0.180115 loss)
I0429 21:35:53.234917 11879 solver.cpp:486] Iteration 3580, lr = 0.005
I0429 21:36:13.558177 11879 solver.cpp:294] Iteration 3600, Testing net (#0)
I0429 21:39:12.481173 11879 solver.cpp:343]     Test net output #0: accuracy = 0.635312
I0429 21:39:12.481405 11879 solver.cpp:343]     Test net output #1: loss = 1.721 (* 1 = 1.721 loss)
I0429 21:39:12.747273 11879 solver.cpp:214] Iteration 3600, loss = 0.107474
I0429 21:39:12.747313 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:39:12.747325 11879 solver.cpp:229]     Train net output #1: loss = 0.107474 (* 1 = 0.107474 loss)
I0429 21:39:12.747334 11879 solver.cpp:486] Iteration 3600, lr = 0.005
I0429 21:39:36.801862 11879 solver.cpp:214] Iteration 3620, loss = 0.109209
I0429 21:39:36.801901 11879 solver.cpp:229]     Train net output #0: accuracy = 1
I0429 21:39:36.801914 11879 solver.cpp:229]     Train net output #1: loss = 0.109209 (* 1 = 0.109209 loss)
I0429 21:39:36.801923 11879 solver.cpp:486] Iteration 3620, lr = 0.005
I0429 21:39:58.489560 11879 solver.cpp:214] Iteration 3640, loss = 0.308074
I0429 21:39:58.489691 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:39:58.489719 11879 solver.cpp:229]     Train net output #1: loss = 0.308074 (* 1 = 0.308074 loss)
I0429 21:39:58.489740 11879 solver.cpp:486] Iteration 3640, lr = 0.005
I0429 21:40:19.321558 11879 solver.cpp:214] Iteration 3660, loss = 0.0558808
I0429 21:40:19.321627 11879 solver.cpp:229]     Train net output #0: accuracy = 1
I0429 21:40:19.321660 11879 solver.cpp:229]     Train net output #1: loss = 0.0558805 (* 1 = 0.0558805 loss)
I0429 21:40:19.321681 11879 solver.cpp:486] Iteration 3660, lr = 0.005
I0429 21:40:40.582756 11879 solver.cpp:214] Iteration 3680, loss = 0.11844
I0429 21:40:40.582926 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:40:40.582959 11879 solver.cpp:229]     Train net output #1: loss = 0.118439 (* 1 = 0.118439 loss)
I0429 21:40:40.582988 11879 solver.cpp:486] Iteration 3680, lr = 0.005
I0429 21:41:01.788004 11879 solver.cpp:214] Iteration 3700, loss = 0.354129
I0429 21:41:01.788043 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:41:01.788058 11879 solver.cpp:229]     Train net output #1: loss = 0.354129 (* 1 = 0.354129 loss)
I0429 21:41:01.788065 11879 solver.cpp:486] Iteration 3700, lr = 0.005
I0429 21:41:22.974797 11879 solver.cpp:214] Iteration 3720, loss = 0.0877912
I0429 21:41:22.974951 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:41:22.974982 11879 solver.cpp:229]     Train net output #1: loss = 0.0877908 (* 1 = 0.0877908 loss)
I0429 21:41:22.975008 11879 solver.cpp:486] Iteration 3720, lr = 0.005
I0429 21:41:44.285742 11879 solver.cpp:214] Iteration 3740, loss = 0.0688275
I0429 21:41:44.285783 11879 solver.cpp:229]     Train net output #0: accuracy = 1
I0429 21:41:44.285804 11879 solver.cpp:229]     Train net output #1: loss = 0.0688271 (* 1 = 0.0688271 loss)
I0429 21:41:44.285820 11879 solver.cpp:486] Iteration 3740, lr = 0.005
I0429 21:42:05.105613 11879 solver.cpp:214] Iteration 3760, loss = 0.0951454
I0429 21:42:05.105814 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:42:05.105836 11879 solver.cpp:229]     Train net output #1: loss = 0.095145 (* 1 = 0.095145 loss)
I0429 21:42:05.105850 11879 solver.cpp:486] Iteration 3760, lr = 0.005
I0429 21:42:25.888562 11879 solver.cpp:214] Iteration 3780, loss = 0.177459
I0429 21:42:25.888610 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:42:25.888624 11879 solver.cpp:229]     Train net output #1: loss = 0.177459 (* 1 = 0.177459 loss)
I0429 21:42:25.888634 11879 solver.cpp:486] Iteration 3780, lr = 0.005
I0429 21:42:50.783818 11879 solver.cpp:294] Iteration 3800, Testing net (#0)
I0429 21:45:22.778625 11879 solver.cpp:343]     Test net output #0: accuracy = 0.582344
I0429 21:45:22.778743 11879 solver.cpp:343]     Test net output #1: loss = 1.79118 (* 1 = 1.79118 loss)
I0429 21:45:23.052253 11879 solver.cpp:214] Iteration 3800, loss = 0.385772
I0429 21:45:23.052289 11879 solver.cpp:229]     Train net output #0: accuracy = 0.84375
I0429 21:45:23.052310 11879 solver.cpp:229]     Train net output #1: loss = 0.385771 (* 1 = 0.385771 loss)
I0429 21:45:23.052323 11879 solver.cpp:486] Iteration 3800, lr = 0.005
I0429 21:45:46.727082 11879 solver.cpp:214] Iteration 3820, loss = 0.232627
I0429 21:45:46.727123 11879 solver.cpp:229]     Train net output #0: accuracy = 0.875
I0429 21:45:46.727143 11879 solver.cpp:229]     Train net output #1: loss = 0.232627 (* 1 = 0.232627 loss)
I0429 21:45:46.727159 11879 solver.cpp:486] Iteration 3820, lr = 0.005
I0429 21:46:08.017345 11879 solver.cpp:214] Iteration 3840, loss = 0.260979
I0429 21:46:08.017509 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:46:08.017534 11879 solver.cpp:229]     Train net output #1: loss = 0.260979 (* 1 = 0.260979 loss)
I0429 21:46:08.017546 11879 solver.cpp:486] Iteration 3840, lr = 0.005
I0429 21:46:29.697867 11879 solver.cpp:214] Iteration 3860, loss = 0.109004
I0429 21:46:29.697904 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:46:29.697926 11879 solver.cpp:229]     Train net output #1: loss = 0.109003 (* 1 = 0.109003 loss)
I0429 21:46:29.697939 11879 solver.cpp:486] Iteration 3860, lr = 0.005
I0429 21:46:51.130161 11879 solver.cpp:214] Iteration 3880, loss = 0.168133
I0429 21:46:51.130249 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:46:51.130266 11879 solver.cpp:229]     Train net output #1: loss = 0.168132 (* 1 = 0.168132 loss)
I0429 21:46:51.130275 11879 solver.cpp:486] Iteration 3880, lr = 0.005
I0429 21:47:12.822417 11879 solver.cpp:214] Iteration 3900, loss = 0.33413
I0429 21:47:12.822454 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:47:12.822468 11879 solver.cpp:229]     Train net output #1: loss = 0.33413 (* 1 = 0.33413 loss)
I0429 21:47:12.822477 11879 solver.cpp:486] Iteration 3900, lr = 0.005
I0429 21:47:34.018496 11879 solver.cpp:214] Iteration 3920, loss = 0.304802
I0429 21:47:34.018731 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:47:34.018756 11879 solver.cpp:229]     Train net output #1: loss = 0.304802 (* 1 = 0.304802 loss)
I0429 21:47:34.018769 11879 solver.cpp:486] Iteration 3920, lr = 0.005
I0429 21:47:55.249810 11879 solver.cpp:214] Iteration 3940, loss = 0.109346
I0429 21:47:55.249843 11879 solver.cpp:229]     Train net output #0: accuracy = 0.9375
I0429 21:47:55.249855 11879 solver.cpp:229]     Train net output #1: loss = 0.109346 (* 1 = 0.109346 loss)
I0429 21:47:55.249864 11879 solver.cpp:486] Iteration 3940, lr = 0.005
I0429 21:48:16.522712 11879 solver.cpp:214] Iteration 3960, loss = 0.189739
I0429 21:48:16.522893 11879 solver.cpp:229]     Train net output #0: accuracy = 0.96875
I0429 21:48:16.522917 11879 solver.cpp:229]     Train net output #1: loss = 0.189739 (* 1 = 0.189739 loss)
I0429 21:48:16.522930 11879 solver.cpp:486] Iteration 3960, lr = 0.005
I0429 21:48:37.280024 11879 solver.cpp:214] Iteration 3980, loss = 0.176948
I0429 21:48:37.280077 11879 solver.cpp:229]     Train net output #0: accuracy = 0.90625
I0429 21:48:37.280092 11879 solver.cpp:229]     Train net output #1: loss = 0.176948 (* 1 = 0.176948 loss)

